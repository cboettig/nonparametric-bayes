---
layout: 12pt,review
linenumbers: true
title: "Supplement for: Avoiding tipping points in fisheries management through Gaussian Process Dynamic Programming"
author: 
  - name: Carl Boettiger
    affiliation: cstar
    email: cboettig(at)gmail.com
    footnote: Corresponding author
  - name: Marc Mangel
    affiliation: cstar
  - name: Stephan Munch
    affiliation: noaa
address: 
  - code: cstar
    address: | 
      Center for Stock Assessment Research, 
      Department of Applied Math and Statistics, 
      University of California, Mail Stop SOE-2,
      Santa Cruz, CA 95064, USA
  - code: noaa
    address: | 
      Southwest Fisheries Science Center, 
      National Oceanic and Atmospheric Administration, 
      110 Shaffer Road, Santa Cruz, CA 95060, USA


bibliography: components/references.bib
csl: components/ecology.csl
documentclass: components/elsarticle

## rmarkdown render options
output:
  pdf_document:
    fig_caption: true
    keep_tex: true

---


```{r knit, include=FALSE, eval=FALSE}
library("methods")
library("rmarkdown")
render("manuscript.Rmd")
```

```{r supplement-caching, include=FALSE}
library("knitr")
basename <- "supplement"
opts_chunk$set(fig.path = paste("components/figure/", basename, "-", sep=""),
               cache.path = paste("components/cache/", basename, "/", sep=""))
opts_chunk$set(cache = 2) 
opts_chunk$set(tidy=FALSE, warning=FALSE, message=FALSE, 
               comment = NA, verbose = TRUE, echo=FALSE)

opts_chunk$set(dev.opts=c(version="1.7"), dev="pdf")

```

\tableofcontents


\appendix
\renewcommand*{\thefigure}{S\arabic{figure}}
\renewcommand*{\thetable}{S\arabic{table}}
\setcounter{figure}{0}
\setcounter{table}{0}

<!--
Table of contents? 
-->



# Code #

All code used in producing this analysis has been embedded into the
manuscript sourcefile using the Dynamic Documentation tool, `knitr`
for the R language [@Xie_2013], available at 
[github.com/cboettig/nonparametric-bayes/](https://github.com/cboettig/nonparametric-bayes/)

To help make the mathematical and computational approaches presented
here more accessible, we provide a free and open source (MIT License)
R package that implements the GPDP process as it is presented here.
Users should note that at this time, the R package has been developed
and tested explicitly for this analysis and is not yet intended as a
general purpose tool.  The manuscript source-code described above
illustrates how these functions are used in this analysis. This
package can be installed following the directions above.


## Dependencies & Reproducibility ##

The code provided should run on any common platform (Windows, Mac or Linux)
that has R and the necessary R packages installed (including support for
the jags Gibbs sampler).  The DESCRIPTION file of our R package, `nonparametricbayes`,
lists all the software required to use these methods. Additional software requirements
for the other comparisons shown here, such as the Gibbs sampling for the parametric models,
are listed under the Suggested packages list.

Nonetheless, installing the dependencies needed is not a trivial task, and may 
become more difficult over time as software continues to evolve.  To facilitate
reuse, we also provide a Dockerfile and Docker image that can be used to replicate
and explore the analyses here by providing a copy of the computational environment
we have used, with all software installed. Docker sofware (see [docker.com](http://www.docker.com))
runs on most platforms as well as cloud servers. Use the command:

    docker run -dP cboettig/nonparametric-bayes

to launch an RStudio instance with the necessary software already installed. See the 
Rocker-org project, [github.com/rocker-org](https://github.com/rocker-org) for more 
detailed documentation on using Docker with R.


# Data #

## Dryad Data Archive ##

While the data can be regenerated using the code provided, for convenience
CSV files of the data shown in each graph are made available on Dryad,
along with the source `.Rmd` files for the manuscript and supplement
that document them. 


## Training data description ##

Each of our models $f(S_t)$ must be estimated from training data, which
we simulate from the Allen model with parameters $r = $ `r p[1]`, 
$K =$ `r p[2]`, $C =$ `r p[3]`, and  $\sigma_g =$ `r sigma_g` for $T=$ `r Tobs`
timesteps, starting at initial condition $X_0 = $ `r Xo`.  The training
data can be seen in Figure 1 and found in the table `figure1.csv`.

## Training data for sensitivity analyses ##

A further 96 unique randomly generated training data sets are generated
for the sensitivity analysis, as described in the main text.  The code
provided replicates the generation of these sets.


# Model performance outside the predicted range (Fig S1) #


Figure S1 illustrates the performance of the GP and parametric models
outside the observed training data. The mean trajectory under the
underlying model is shown by the black dots, while the corresponding
prediction made by the model shown by the box and whiskers plots.
Predictions are based on the true expected value in the previous time
step.  Predicted distributions that lie entirely above the expected
dynamics indicate the expectation of stock sizes higher than what is
actually expected. The models differ both in their expectations and
their uncertainty (colored bands show two standard deviations away).
Note that the GP is particularly uncertain about the dynamics relative
to structurally incorrect models like the Ricker.


```{r figure_S1, fig.width=6, fig.height=4, fig.cap="Outside the range of the training data (Figure 1), the true dynamics (black dots) fall outside the uncertainty (two standard deviations, colored bands) of the structurally incorrect parametric models (Ricker, Myers), but inside the uncertainty predicted by the GP. Points show the stock size simulated by the true model.  Overlay shows the range of states predicted by each model, based on the state observed in the previous time step. The Ricker model always (wrongly) predicts positive population growth, while the actual population shrinks in each step as the initial condition falls below the Allee threshold of the underlying model (Allen).  Note that because it does not assume a parametric form but instead relies more directly on the data, the GP is both more pessimistic and more uncertain about the future state than the parametric models.", dependson="plot-options"}
y <- numeric(8)
y[1] <- 4.5
for(t in 1:(length(y)-1))
      y[t+1] = z_g() * f(y[t], h=0, p=p)
# predicts means, does not reflect uncertainty estimate!
crash_data <- step_ahead_posteriors(y)
crash_data <- subset(crash_data, variable %in% c("GP", "Allen", "Ricker", "Myers"))
ggplot(crash_data) + 
  geom_boxplot(aes(as.factor(as.integer(time)), value, 
                   fill = variable, col=variable), 
               outlier.size=1, position="identity") + 
#  geom_line(aes(time, value, col = variable, 
#            group=interaction(L1,variable))) + 
  geom_point(aes(time, stock), size = 3) + 
  scale_fill_manual(values=colorkey[c("GP", "Allen", "Ricker", "Myers")]) +  
  scale_colour_manual(values=colorkey[c("GP", "Allen", "Ricker", "Myers")]) +  
  facet_wrap(~variable) + 
  theme(legend.position="none") + xlab("time") + ylab("stock size") 

write.csv(crash_data, "components/data/figureS1.csv")
```

```{r S1_eml, eval=FALSE}
## Forgo the EML generation, the Rmd files provide better documentation at this stage.
library(EML)
me <- "Carl Boettiger <cboettig@ropensci.org>"
models <- levels(crash_data$variable)
names(models) <- models
col.defs <- c("time", "fish stock", "model", "value", "replicate")
unit.defs <- list("number", "number", models, "number", "number")
col.classes <- sapply(crash_data, class)
eml_write("components/data/figureS1.csv", col.classes = col.classes, col.defs=col.defs,unit.defs=unit.defs,creator=me, title="Figure S1", file="components/data/README_S1.xml")
```

\newpage



# Further sensitivity analysis (Fig S2 - 3) #


We perform 2 sensitivity analyses. The first focuses on illustrating the robustness of the
approach to the two parameters that most influence stochastic transitions across the tipping 
point: the position of the Allee threshold and the scale of the noise (Fig S2).

Changing the intensity of the stochasticity or the distance between stable and unstable steady states
does not impact the performance of the GP relative to the optimal solution
obtained from the true model and true parameters.  The parametric models are
more sensitive to this difference.  Large values of $\sigma$ relative to the distance between the stable and unstable
point increases the chance of a stochastic transition below the tipping point.  More precisely,
if we let $L$ be the distance between the stable and unstable steady states, then the probability that fluctuations drive the population across the unstable steady state scales as

$\exp\left(\frac{L^2}{\sigma^2}\right)$

(see @Gardiner2009 or @Mangel2006 for the derivation).

Thus, the impact of using a model that  underestimates the risk of harvesting
beyond the critical point is considerable, since this such a situation
occurs more often.  Conversely, with large enough distance between the
optimal escapement and unstable steady state relative to $\sigma$, the chance
of a transition becomes vanishingly small and all models can be estimated 
near-optimally. Models that underestimate the cost incurred by population
sizes fluctuating significantly below the optimal escapement level will
not perform poorly as long as those fluctuations are sufficiently small.
Fig S2 shows the net present value of managing under teh GPDP remains
close to the optimal value (ratio of 1), despite varying across either
noise level or the the position of the allee threshold. 



```{r figure_S2, fig.width=6, fig.height=3, dependson=c("sensitivity-trends"), fig.cap="The effect of increasing noise or decreasing Allee threshold levels on the net present value of the fishery when managed under the GPDP, relative to managing under the true model (with known parameters).  Other than the focal parameter (stochasticity, Allee threshold), other parameters are held fixed as above to illustrate this effect.", cache=FALSE}
plot_sigmas <- ggplot(vary_sigma, aes(noise, value)) + 
  geom_point(size=2) + ylab("Net present value") + 
  xlab("Level of growth stochasticity")
plot_allees <- ggplot(vary_allee, aes(allee, value)) + 
  geom_point(size=2)+ ylab("Net present value") + 
  xlab("Allee threshold stock size")
multiplot(plot_sigmas, plot_allees, cols=2) 
write.csv(vary_sigma, "components/data/figureS2a.csv")
write.csv(vary_allee, "components/data/figureS2b.csv")
```



The Latin hypercube approach systematically varies all combinations of
parameters, providing a more general test than varying only one parameter
at a time.  We loop across eight replicates of three different randomly
generated parameter sets for each of two different generating models
(Allen and Myers) over two different noise levels (0.01 and 0.05),
for a total of 8 x 3 x 2 x 2 = 96 scenarios. The Gaussian Process performs
nearly optimally in each case, relative to the optimal solution with no
parameter or model uncertainty (Figure S10, appendix).  



```{r sensitivity-calc}
source("components/sensitivity.R")

models <- c("Myers","Allen")

parameters <- list(
  Myers = list(
    c(r=1.5 + rnorm(1, 0, 1), theta=2 + rnorm(1, 0, 1), K=10 + rnorm(1, 0, 1)),
    c(r=1.5 + rnorm(1, 0, 1), theta=2.5 + rnorm(1, 0, 1), K=10 + rnorm(1, 0, 1))),
  Allen = list(
    c(r=2 + rnorm(1, 0, 1), K=10 + rnorm(1, 0, 1), C=4 + rnorm(1, 0, 1)),
    c(r=2 + rnorm(1, 0, 1), K=10 + rnorm(1, 0, 1), C=4 + rnorm(1, 0, 1)))
)
nuisance_pars <- c("sigma_g")
nuisance_values <- list(sigma_g = c(0.01, 0.05))
```

```{r allensets}
model <- "Allen"
allen1.01 <- sensitivity(model, 
                   parameters = parameters[[model]][[1]], 
                   nuisance = c(sigma_g = nuisance_values$sigma_g[1]), 
                   seed=c(1111, 2222, 3333))
allen2.01 <- sensitivity(model, 
                   parameters = parameters[[model]][[2]], 
                   nuisance = c(sigma_g = nuisance_values$sigma_g[1]), 
                   seed=c(1111, 2222, 3333))
allen1.05 <- sensitivity(model, 
                   parameters = parameters[[model]][[1]], 
                   nuisance = c(sigma_g = nuisance_values$sigma_g[2]), 
                   seed=c(1111, 2222, 3333))
allen2.05 <- sensitivity(model, 
                   parameters = parameters[[model]][[2]], 
                   nuisance = c(sigma_g = nuisance_values$sigma_g[2]), 
                   seed=c(1111, 2222, 3333))
```

```{r myerssets}
model <- "Myers"
Myers1.01 <- sensitivity(model, 
                   parameters = parameters[[model]][[1]], 
                   nuisance = c(sigma_g = nuisance_values$sigma_g[1]), 
                   seed=c(1111, 2222, 3333))
Myers2.01 <- sensitivity(model, 
                   parameters = parameters[[model]][[2]], 
                   nuisance = c(sigma_g = nuisance_values$sigma_g[1]), 
                   seed=c(1111, 2222, 3333))
Myers1.05 <- sensitivity(model, 
                   parameters = parameters[[model]][[1]], 
                   nuisance = c(sigma_g = nuisance_values$sigma_g[2]), 
                   seed=c(1111, 2222, 3333))
Myers2.05 <- sensitivity(model, 
                   parameters = parameters[[model]][[2]], 
                   nuisance = c(sigma_g = nuisance_values$sigma_g[2]), 
                   seed=c(1111, 2222, 3333))

## Assemble into data.frame
allen_dat <- rbind(allen1.01, allen1.05, allen2.01, allen2.05) 
m <- rbind(Myers1.01, Myers1.05, Myers2.01, Myers2.05)
myers_dat <- m[c(1:2,4,3,5:8)]
names(myers_dat) <- names(allen_dat)
model_dat <- rbind(allen_dat, myers_dat)
dat <- model_dat
dat$pars.r <- factor(dat$pars.r, labels=c("A", "B", "C", "D"))
dat <- dat[c(1:2,5:6, 8, 7)]
dat$noise <- factor(dat$noise)
names(dat) <- c("model", "parameters", "replicate", "simulation", "noise", "value")

## Extract acutal parameter values corresponding to each parameter set
p1 = as.numeric(levels(factor(model_dat$pars.r)))
p2 = as.numeric(levels(factor(model_dat$pars.K)))
p3 = as.numeric(levels(factor(model_dat$pars.C)))

set.A = c(r = p1[1], K = p2[1], theta = p3[1])
set.B = c(r = p1[2], K = p2[2], theta = p3[2])
set.C = c(r = p1[3], K = p2[3], C = p3[3])
set.D = c(r = p1[4], K = p2[4], C = p3[4])
AllenParameterSets <- rbind(set.A, set.B)
MyersParameterSets <- rbind(set.C, set.D)

sensitivity_dat <- dat
```

```{r figure_S3, fig.height=6, fig.width=6, dependson=c("sensitivity-calc", "export-data"), fig.cap="Sensitivity Analysis.  Histograms shows the ratio of the realized net present value derived when managing under the GPDP over the optimal value given the true model and true parameters. Values of 1 indicate optimal performance. Columns indicate different models, rows different noise levels, and colors indicate the parameter set used. Grouped over stochastic replicates applying the contol policy and stochastic replicates of training data generated from the model indicated, see raw data for details. Randomly chosen parameter values for the models shown in tables below."}
ggplot(sensitivity_dat) + 
  geom_histogram(aes(value, fill=parameters)) + 
  xlim(0,1.0) + 
  theme_bw() + 
  xlab("value as fraction of the optimal") + 
  facet_grid(noise~model)
write.csv(sensitivity_dat, "components/data/figureS3.csv") 
```




```{r AllenSetsTable, results="asis"}
pandoc.table(AllenParameterSets, caption="Randomly chosen parameter sets for the Allen models in Figure S3." )
```
```{r MyersSetsTable, results="asis"}
pandoc.table(MyersParameterSets, caption="Randomly chosen parameter sets for the Myers models in Figure S3." )
```

\newpage


# MCMC analyses #

This section provides figures and tables showing the traces from each of the MCMC runs used to estimate the parameters of the models presented, along with the resulting posterior distributions for each parameter.  Priors usually appear completely falt when shown against the posteriors, but are summarized by tables the parameters of their corresponding distributions for each case. 


## GP MCMC (Fig S4-5) ##

```{r figure_S4, fig.cap = "Traces from the MCMC estimates of the GP model show reasonable mixing (no trend) and sampling rejection rate (no piecewise jumps)", dependson="plot-options", fig.width=4, fig.height=4}
gp_assessment_plots$traces_plot
```


```{r figure_S5, fig.cap="Posterior distributions from the MCMC estimate of the GP model. Prior curves shown in red; note the posterior distributions are significantly more peaked than the priors, showing that the data has been informative and is not driven by the priors.", fig.width=4, fig.height=4}
gp_assessment_plots$posteriors_plot
write.csv(tgp_dat,"components/data/figureS4-5.csv")
```


\newpage
\newpage


## Ricker Model MCMC (Fig S6-7) ##

```{r figure_S6, fig.height=6, fig.cap="Traces from the MCMC estimates of the Ricker model show reasonable mixing (no trend) and sampling rejection rate (no piecewise jumps). stdQ refers to the estimate of $\\sigma$; deviance is -2 times the log likelihood. ", fig.width=4}
ggplot(ricker_posteriors) + 
  geom_line(aes(index, value)) + # priors, need to fix order though
  facet_wrap(~ variable, scale="free_y", ncol=1)
```

```{r figure_S7, fig.cap="Posteriors from the MCMC estimate of the Ricker model. Note that the model estimates a carrying capacity $K$ very close to the true equilibrium where most of the observations were made, but is less certain about the growth rate.", fig.width=4, fig.height=4}
ggplot(ricker_posteriors, aes(value)) + 
  stat_density(geom="path", position="identity") +
  facet_wrap(~ variable, scale="free", ncol=2)
write.csv(ricker_posteriors, "components/data/figureS6-7.csv")
```


```{r Table S1, results = "asis"}
pander::pandoc.table(ricker_priors_xtable,
  caption = "Parameterization range for the uniform priors in the Ricker model")
```

\newpage
\newpage 

## Myers Model MCMC (Fig S8-9) ## 


```{r figure_S8, fig.height=6, fig.cap="Traces from the MCMC estimates of the Myers model show reasonable mixing (no trend) and sampling rejection rate (no piecewise jumps). stdQ refers to the estimate of $\\sigma$; deviance is -2 times the log likelihood.", fig.width=4}
ggplot(myers_posteriors) + 
  geom_line(aes(index, value)) + # priors, need to fix order though
  facet_wrap(~ variable, scale="free_y", ncol=1)
```

```{r figure_S9, fig.cap="Posterior distributions from the MCMC estimates of the Myers model. Note that with more free parameters, the posteriors reflect greater uncertainty.  In particular, the parameter $\\theta$ includes values both above 2, resulting in a tipping point, and below 2, where no tipping point exists in the model.  Though the dynamic program will integrate over the full distribution, including those values corresponding to tipping points, the weight of the model lies in the region without tipping points.", fig.width=4, fig.height=6}
ggplot(myers_posteriors, aes(value)) + 
  stat_density(geom="path", position="identity") +
  facet_wrap(~ variable, scale="free", ncol=2)
write.csv(myers_posteriors, "components/data/figureS8-9.csv")
```


```{r TableS2, results="asis"}
pander::pandoc.table(myers_priors_xtable,
           caption = "Parameterization range for the uniform priors in the Myers model")
```

\newpage 
\newpage 

## Allen Model MCMC (Fig S10-11) ##


```{r figure_S10, fig.height=6, fig.cap="Traces from the MCMC estimates of the Allen model show reasonable mixing (no trend) and sampling rejection rate (no piecewise jumps). stdQ refers to the estimate of $\\sigma$; deviance is -2 times the log likelihood.", fig.width=4}
ggplot(allen_posteriors) + 
  geom_line(aes(index, value)) + # priors, need to fix order though
  facet_wrap(~ variable, scale="free_y", ncol=1)
```

```{r figure_S11, fig.cap="Posteriors from the MCMC estimate of the Allen model. The Allen model is the structurally correct model.  Despite potential identfiability issues in distinguishing between the stable and unstable points ($K$ and $\\theta$ respectively), the posterior estimates successfully reflect both the the upper stable point ($K$), as well as the significant probabilty of a tipping point ($\\theta$) somewhere between $K$ and extinction (0).", fig.width=4, fig.height=6}
ggplot(allen_posteriors, aes(value)) + 
  stat_density(geom="path", position="identity") +
  facet_wrap(~ variable, scale="free", ncol=2)
write.csv(allen_posteriors, "components/data/figureS10-11.csv")
```


```{r TableS3, results = "asis"}
pander::pandoc.table(allen_priors_xtable,
  caption = "Parameterization range for the uniform priors in the Allen model")
```

```{r unlink, include=FALSE}
unlink("ricker_process.bugs")
unlink("allen_process.bugs")
unlink("myers_process.bugs")
```
