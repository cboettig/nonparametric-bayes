% Avoiding tipping points in the management of ecological systems: a non-parametric Bayesian approach

<!-- Run R code for analysis, to be called by figures -->
```{r plot-options, cache=FALSE, message=FALSE, warning=FALSE, include=FALSE}
library(nonparametricbayes) 
opts_chunk$set(external=TRUE)
read_chunk("../examples/BUGS/external-chunks.R")

opts_chunk$set(tidy=FALSE, warning=FALSE, message=FALSE, cache=1, 
               comment=NA, verbose=TRUE, fig.width=6, fig.height=4)
 
# Name the cache path and fig.path based on filename...
opts_chunk$set(fig.path = paste("figure/",
                                gsub(".Rmd", "", knitr:::knit_concord$get('infile')),
                                "-", sep=""),
               cache.path = paste("cache/", 
                                  gsub(".Rmd", "", knitr:::knit_concord$get('infile') ), 
                                "/", sep=""))

toggle = "markup" #"hide"  # toggles `results` chunk option 

library(ggplot2) 
theme_set(theme_bw(base_size=12))
cbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", 
               "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
```

```{r posterior-mode}
```
```{r stateeq}
```
```{r sdp-pars, dependson="stateeq"}
```
```{r obs, dependson="sdp-pars"}
```


```{r mle, dependson="obs"}
```
```{r mle-output, dependson="mle", results=toggle}
```


```{r gp-priors}
```
```{r gp, dependson=c("gp-priors", "obs")}
```
```{r gp_traces_densities, dependson="gp"}
```
```{r gp-output, dependson="gp", results=toggle}
```


```{r jags-setup}
```
```{r common-priors}
```
```{r allen-model}
```
```{r allen-priors, dependson="common-priors"}
```
```{r allen-mcmc, dependson=c("allen-model", "allen-pars", "jags-setup"), results=toggle}
```
```{r allen-traces, dependson="allen-mcmc"}
```
```{r allen-posteriors, dependson=c("allen-traces", "allen-priors")}
```
```{r allen-output, dependson=c("posterior-mode", "allen-traces"), results=toggle}
```


```{r ricker-model}
```
```{r ricker-priors, dependson="common-priors"}
```
```{r ricker-mcmc, dependson="ricker-model", results=toggle}
```
```{r ricker-traces, dependson="ricker-mcmc"}
```
```{r ricker-posteriors, dependson=c("ricker-traces", "ricker-priors")}
```
```{r ricker-output, dependson=c("posterior-mode", "ricker-traces"), results=toggle}
```


```{r myers-model}
```
```{r myers-priors}
```
```{r myers-mcmc, dependson="myers-model", results=toggle}
```
```{r myers-traces, dependson="myers-mcmc"}
```
```{r myers-posteriors, dependson="myers-traces"}
```
```{r myers-output, dependson=c("posterior-mode", "myers-traces"), results=toggle}
```


```{r assemble-models, dependson=c("myers-output", "ricker-output", "allen-output", "gp-output", "mle-output")}
```
```{r gp-opt, dependson="gp-output"}
```
```{r mle-opt, dependson="mle-output"}
```
```{r allen-opt, dependson="allen-output"}
```
```{r ricker-opt, dependson="ricker-output"}
```
```{r myers-opt, dependson="myers-output"}
```
```{r assemble-opt, dependson=c("gp-opt", "mle-opt", "allen-opt", "ricker-opt", "myers-opt")}
```
```{r sims, dependson="assemble-opt"}
```


```{r profits, dependson="sims", results=toggle}
```
```{r deviances, dependson=c("posterior-mode", "myers-output", "ricker-output", "allen-output", "gp-output", "mle-output"), results=toggle}
```


Abstract
========

Model uncertainty and limited data coverage are fundamental challenges to
robust ecosystem management.  These challenges are acutely highlighted
by concerns that many ecological systems may contain tipping points.
Before a collapse, we do not know where the tipping points lie, if the
exist at all.  Hence, we know neither a complete model of the system
dynamics nor do we have access to data in some large region of state-space
where such a tipping point might exist.  These two sources of uncertainty
frustrate state-of-the-art parametric approaches to decision theory
and optimal control.  I will illustrate how a non-parametric approach
using a Gaussian Process prior provides a more flexible representation
of this inherent uncertainty.  Consequently, we can adapt the Gaussian
Process prior to a stochastic dynamic programming framework in order to
make robust management predictions under both model and uncertainty and
limited data.


Introduction
============

<!--
Very briefly set the stage: (see related papers)
- Decision-theory / optimal control framework
- Fisheries context 
-->

<!-- FIXME -->


The sudden collapse of fisheries and other ecosystems is an increasingly
widespread phenomenon and a pressing concern for ecological management
and conservation.  Ecological dynamics are frequently complex and difficult to 
measure, making uncertainty in our understanding a prediction a persistent
challenge to effective management. 
Decision-theoretic approaches provide a framework to determine the best 
sequence of actions in face of uncertainty, but only when that uncertainty
can be meaningfully quantified [@Fischer2009].  



Uncertainty enters at many levels <!-- enters what -->
management


- Why fisheries 

The economic value and ecological concern have made marine
fisheries the crucible for much of the founding work [@Gordon1954;
@Reed1979; @May1979; @Ludwig1982] in managing ecosystems under
uncertainty.  Global trends [@Worm2006] and controversy [@Hilborn2007;
@Worm2009] have made understanding these challenges all the more pressing.




<!-- Other reasons for failure see Sethi-->


@Fischer 
@Sethi2005, @Peretti, @Munch, 


(Classical division)

- Dynamic uncertainty (stochasticity)

From [Clark (1976)]() to [Reed (1979)]()

Other sources of uncertainty [Roughgarden & Smith 1996](), [Sethi _et al._ (2005)]()


- Parametric uncertainty <!-- ugh, be more consise and less annoying-->


As the parameter values for these models must be estimated from limited data,  
there will always be some uncertainty associated with these values.  This uncertainty
further compounds the intrinsic variability introduced by demographic or environmental 
noise.  The degree of uncertainty in the parameter values can be inferred from the data
and reflected in the estimates of the transition probabilities.  

[@Mangel1985; @Schapaugh2013]


[Ludwig & Walters 1982](http://doi.org/10.1016/0304-3800(82)90023-0 "Optimal harvesting with imprecise parameter estimates")

- Structural uncertainty <!-- ugh, be more consise and less annoying-->

Estimates of parameter uncertainty are only as good as the parametric
models themselves.  Often we do not understand the system dynamics well
enough to know if a model provides a good approximation over the relevant
range of states and timescales (criteria that we loosely refer to as
defining the "right" or "true" model.)  So called structural or model
uncertainty is a more difficult problem than parametric uncertainty.
Typical solutions involve either model choice, model averaging, or
introducing yet greater model complexity of which others may be special
cases (model averaging being one such way to construct such a model)
[@Williams2001; @Athanassoglou2012; @Cressie2009].  Even setting aside
other computational and statistical concerns (e.g. [@Cressie2009]), these
approaches do not address our second concern - representing uncertainty
outside the observed data range.



[@Cressie2009](http://dx.doi.org/10.1890/07-0744.1 "Accounting for uncertainty in ecological analysis: the strengths and limitations of hierarchical statistical modeling."). 

- Limits of state space 

Resource management and conservation planning seek to determine the optimal set of feasible actions to maximize the value of some objectives (see [@Halpern2012])  Process error, measurement error, implementation error [@Reed1979, @Clark1986, @Roughgarden1996, @Sethi2005].  These sources of stochasticity in turn mean that model parameters can only be estimated approximately, requiring parametric uncertainty also be considered [@Ludwig1982, ].  


The three sources of uncertainty: stochasticity (in process, measurement, and implementation; though we focus on process-noise only for simplicity), parametric uncertainty, and structural uncertainty, are familiar challenges.  

Of all sources of uncertainty, this last has received the least attention.[^1] 


Often the set of feasible states is larger than the range of the observed states.  Though most systems subject to some degree of stochasticity can enter a state outside previously observed values by chance alone (such as a particularly low or high nutrient year), this concern is most keenly felt in the decision-theoretic context. If we are observing the fluctuations of a given fish stock over many years under a fixed harvesting pressure, we might develop and test a model that could reasonably predict the frequency of a deviation of a given size, even when such a deviation has not been previously observed. 

(The same analogy might be made to predicting hurricanes or other extreme weather events from historical data, which may be more accurately predicted in a constant climate than in one being perturbed).  


Given adequate observations of a system  

One must consider actions or policy under which the system has not yet been observed, 

<!-- What do we call this?  Extrapolation uncertainty?  Pathological Uncertainty? -->


[^1]: The concept of adaptive probing is one area that has explicitly addressed this kind of uncertainty, reaching rather opposite conclusions than what we observe here. Adaptive probing strategies follow from "Dual Control" or "Active Adaptive Management" approaches (e.g. @Ludwig1982) that can trade off short term utility by choosing actions that can reduce uncertainty.  Adaptive probing strategies arise when it is valuable to intentionally force a system far from the observed values even when the expected value such actions is low, as it provides much faster learning and consequent reduction of model uncertainty that can allow greater value to be derived later on.  For instance, @Ludwig1982 show that it may be advantageous to fish an unexploited population very heavily at first to obtain a better estimate of the recruitment rate.  This intuitive strategy when a population is governed by a Ricker or Beverton-Holt-like dynamic would clearly be disastrous if instead the dynamics contained an unforeseen tipping point.  The best way to learn where the edge lies may be to walk up to it, but it is also the most dangerous.  




## Two central challenges: 

- We don't know the model
- We don't have data from where we need it most

## Why we don't know the model

- Complex dynamics  [@Glaser2013](http://doi.org/10.1111/faf.12037 "Complex dynamics may limit prediction in marine fisheries")

- model choice and model averaging approaches

## Why we don't have data where we need it

- Concerns of tipping points 
- Danger of learning 


- _MAP_


Decision making under uncertainty is a ubiquitous challenge of natural 
resource management and conservation. 
Here we illustrate how a stochastic dynamic programming (SDP) algorithm can 
be driven by the predictions from a Gaussian Process (GP).
This provides two distinct advantages compared with contemporary approaches.
First, using a GP sidesteps the need for an accurate model-based description
of the system dynamics (or a model choice or model-averaging approach which
introduces yet more difficulty).  
Second, unlike parametric models which can only reflect 
uncertainty in the corresponding confidence intervals or posterior distributions
of their parameters, the GP approach provides a state-space dependent representation
of uncertainty.  This permits a much greater uncertainty far from the observed data than near the observed 
data.  These features allow the GP-SDP approach to find robust management solutions 
in face of limited data and without knowledge of the correct model structure.  












-  _Note on "not magic"_: honest uncertainty + SDP

The idea that any approach can perform well without either having to
know the model or have particularly good data should immediately draw
suspicion.  The reader must bear in mind that the strength of our approach
comes not from black-box predictive power from such limited information,
but rather, by providing a more honest expression of uncertainty outside
the observed data without sacrificing the predictive capacity near the
observed data. By coupling this more accurate description of what is known
and unknown to the decision-making under uncertainty framework provided
by stochastic dynamic programming, we are able to obtain more robust
management policies than with common parametric modeling approaches.







<!--move to  much later --> 
- Note on terminology: "Non-parametric"  


The term non-parametric to describe Gaussian processes (GP) is unfortunate,
given that the GP models still involve the estimation of parameters. Some 
literature thus uses the term semi-parametric, which merely adds ambiguity 
to the confusion.  Statisticians give two distinct meanings to the term: (a)
referring to a method that does not assume a distribution (e.g. non-parametric bootstrap, order statistics),
and (b) one that does not assume a fixed structure but rather depends on the 
size of the data (e.g. non-parametric regression, non-parametric hierarchical models
such as the Dirichlet process).  Our use is in the latter sense.  

This non-parametric property -- having a structure that is not fixed but 
rather dependent on the data is precisely the property that makes this approach
attractive in face of the limited data sampling challenges discussed above.  
Having fit a parametric model to some data, the model is completely described
by the values (or posterior distributions) of it's parameters.  The non-parametric 
model is not captured by its parameter values or distributions alone -- the 
data points become part of the model.  



- _Note on comparing models_ (via value function rather than by "fit"). 

_Do we need this?_

The nature of decision-making problems provides a convenient way to compare 
models.  Rather than compare models in terms of best fit to data or fret over
the appropriate penalty for model complexity, model performance is defined 
in the concrete terms of the decision-maker's objective function, which we
will take as given. (Much argument can be made over the 'correct' objective
function, e.g. how to account for the social value of fish left in the sea
vs. the commercial value of fish harvested; see @Halpern2013 for further 
discussion of this issue.  Alternatively, we can always compare model performance
across multiple potential objective functions.)  The decision-maker
does not necessarily need a model that provides the best mechanistic understanding
or the best long-term outcome, but rather the one that best estimates the 
probabilities of being in different states as a result of the possible actions. 



## Background on the Gaussian Process

- Definition
- Previous application
- Why it is particularly suited to these two problems
- (Why this is a novel application thereof)

Approach and Methods
====================

### Summary of approach

### Statement of the optimal control problem

- Underlying model 
- Available data 
- Value function



For simplicity we assume profit is simply linear in the realized harvest (only
enforcing the restriction that harvest can not exceed available stock)


### Parametric models

- Statement of the models

We consider three candidate parametric models of the stock-recruitment
dynamics: The Ricker model, the Allen model [Allen 2005](), the Myers
model. The familiar Ricker model involves two parameters, corresponding
to a growth rate and a carrying capacity, and cannot support alternative
stable state dynamics (though as growth rate increases it exhibits a
periodic attractor that proceeds through period-doubling into chaos. We
will generally focus on dynamics below the chaotic threshold for
the purposes of this analysis.) The Allen model resembles the Ricker
dynamics with an added Allee effect parameter [Courchamp](), below
which the population cannot persist.  The Myers model also has three
parameters and contains an Allee threshold, but has compensatory rather
than over-compensatory density dependence (resembling a Beverton-Holt
curve rather than a Ricker curve at high densities.)

We assume multiplicative log-normal noise perturbs the growth predicted 
by the each of the deterministic model skeletons described above. This 
introduces one additional parameter $\sigma$ that must be estimated by each
model. 

<!-- equations just in appendix? -->

As we simulate training data from the Allen model (ref section), we will
refer to this as the structurally correct model.  The Ricker model is
thus a reasonable approximation of these dynamics far from the Allee
threshold (but lacks threshold dynamics), while the Myers model shares
the essential feature of a threshold but differs in the structure. Thus
we have three potential parametric models of the stock dynamics.

- Bayesian inference of parametric models

We infer posterior distributions for the parameters of each model
in a Bayesian context using Gibbs sampling (implemented in R [@RTeam]
using jags, [@R2jags]).  We choose uninformative uniform priors for all
parameters (See Appendix, Figures S1-S3, and Table S1, and the R code
provided). One-step-ahead predictions of these model fits are shown in
Figure 1.

- SDP via parametric models

An optimal policy function is then inferred through stochastic dynamic
programming for each model given the posterior distributions of the
parameter estimates.  This policy maximizes the expectation of the value
function integrated over the parameter uncertainty. (code implementing
this algorithm provided in the Appendix).


### The Gaussian Process model

- Statement of model

... more on GP ... [Munch 2005]()

We also estimate a simple Gaussian Process defined by
a radial basis function kernel of two parameters: $\ell$, which gives
the characteristic length-scale over which correlation between two 
points (e.g. any two points $X_t, X_{t+1}$, and $X_{t+\tau}, X_{t+1+\tau}$)
in state-space decays, and $\sigma$, which gives the scale of the 
process noise by which observations $Y_{t+1}$ may differ from their
predicted values $X_{t+1}$ given an observation of the previous state,
$X_t$. 

- Inference of the model

Also unlike parametric models, this posterior distribution is still
conditional on the training data. As such, the uncertainty near the
observed data.

We use a Metropolis-Hastings Markov Chain Monte Carlo to infer posterior
distributions of the two parameters of the GP (Figure S4, code in
appendix), under weakly informative Gaussian priors (see parameters in
table S5). As the posterior distributions differ substantially from the
priors (Figure S4), we can be assured that most of the information in
the posterior comes from the data rather than the prior belief.


- SDP via the model

Though we are unaware of prior application of this type, it is reasonably
straight-forward to adapt the Gaussian Process for Stochastic Dynamic
Programming.  Recall that unlike the parametric models the Gaussian
process with fixed parameters already predicts a distribution of
curves rather than a single curve. We must first integrate over 
this distribution of curves given a sampling of parameter values drawn
from the posterior distribution of the two GP parameters, before
integrating over the posterior of those parameters themselves.



Results
=======


```{r Figure1, dependson=c("assemble-models"), fig.cap="Graph of the inferred Gaussian process compared to the true process and maximum-likelihood estimated process.  Graph shows the expected value for the function $f$ under each model.  Two standard deviations from the estimated Gaussian process covariance with (light grey) and without (darker grey) measurement error are also shown.  The training data is also shown as black points.  (The GP is conditioned on 0,0, shown as a pseudo-data point). ", include=FALSE}
```
```{r Figureb, dependson=c("assemble-models", "par-fns"), include=TRUE}
```


Figure 1 shows the mean inferred state space dynamics of each model
relative to the true model used to generate the data, predicting the
relationship between observed stock size (x-axis) to the stock size
after recruitment the following year.  All models except the MLE model
estimate a distribution around the means shown here, and all models 
estimate a level of process noise, which is independent of the state
value (x).  Note that in contrast to the  other models shown, the mean
Gaussian process corresponds to a distribution of curves - as indicated
by the gray band - which itself has a mean shown in black.  Note that 
this mean GP is thus more certain of the dynamics in the region where
data is available then where it is not.  

While it would be straight forward to condition the GP on passing through the origin (0,0), the estimate
shown here is based only on the observed data. The observed data from
which each model is estimated is also shown.  The observations come
from only a limited region of state space corresponding to unharvested
or weakly harvested system.  No observations occur at the theoretical
optimum harvest rate or near the tipping point.

```{r Figure2, dependson = c("assemble-opt"), fig.cap="The steady-state optimal policy (infinite boundary) calculated under each model.  Policies are shown in terms of target escapement, $S_t$, as under models such as this a constant escapement policy is expected to be optimal [@Reed1979].", include=TRUE}
```

The resulting optimal management strategy based on each of the inferred
models is shown in Figure 2, against the optimal strategy given the
true underlying dynamics.  Policies are shown in terms of target
escapement, $S_t$.  Under models such as this a constant escapement
policy is expected to be optimal [@Reed1979], whereby population levels
below a certain size $S$ are unharvested, while above that size the harvest
strategy aims to return the population to $S$, resulting in the hockey-stick
shaped policies shown.  


```{r Figure3, dependson=c("sim"), fig.cap="Gaussian process inference outperforms parametric estimates. Shown are 100 replicate simulations of the stock dynamics (eq 1) under the policies derived from each of the estimated models, as well as the policy based on the exact underlying model.",  include=TRUE}
```

The consequences of managing 100 replicate realizations of the 
simulated fishery under each of the policies estimated is shown in Figure 3.  As expected
from the policy curves, the structurally correct model under-harvests,
leaving the stock to vary around it's un-fished optimum.  The structurally
incorrect Ricker model over-harvests the population passed
the tipping point consistently, resulting in the immediate crash of the stock and 
thus derives minimal profits.  


The results shown in Figures 1-3 are not unique to the simulated data or models chosen
here, but arises across a range of parameter values and simulations as shown in the 
supplemental figures.  The results across this range can most easily be compared 
by the relative differences in net present value realized by each of the approaches,
as shown in Figure 4.  The Gaussian Process most consistently realizes a value 
close to the optimal solution, and importantly avoids ever driving the system across
the tipping point, which results in the near-zero value cases in the parametric models.  


```{r Figure4, dependson=c("profits"), fig.cap="Histograms of the realized net present value of the fishery over a range of simulated data and resulting parameter estimates. For each data set, the three models are estimated as described above. Values plotted are the averages of a given policy over 100 replicate simulations. Details and code provided in the supplement.",  include=TRUE}
```

### Figure 1: Fitted Models

- All models fit the data quite well
- Information criteria would pick the simple, incorrect model.


### Figure 2: Inferred Policies

- Inferred policies differ substantially among models
- The structurally correct model and the GP are close to the true model
- alternatives are not close

### Figure 3: Simulated results

- 

### Figure 4: Robustness

- Results hold across range of parameters

(eek, distinguish better between result and discussion?)

Discussion 
==========

- All models are "good fits" to the originally observed data. 

- (Simple model choice immediately leads us astray)




Though simple mechanistically motivated models offer the greatest potential 
to increase our basic understanding of ecological processes [@Cuddington2013; @Geritz2012], 
such models can be not only inaccurate but misleading when relied upon in a
quantitative decision making framework.  

1. We do not know what the correct models are for ecological systems.
1. We have limited data from which to estimate the model -- in particular,
   such models may be misleading in predicting the probability of outcomes
   outside the training data.  

These aspects are common to many conservation decision making problems, which thus merit
greater use of non-parametric approaches that can best take advantage of them.  


### 1. Large uncertainty where the data is poor 

The parametric models perform worst when they propose a management strategy
outside the range of the observed data. The non-parametric Bayesian approach, 
in contrast, allows a predictive model that expresses a great deal of uncertainty
about the probable dynamics outside the observed range, while retaining very
good predictive accuracy in the range observed.  The management policy 
dictated by the GP balance this uncertainty against
the immediate value of the harvest, and act to stabilize the population 
dynamics in a region of state space in which the predictions can be 
reliably reflected by the data.  

### 2. Predictive accuracy where data is good

While expressing larger uncertainty outside the observed data, the GP
can also provide a better fit with smaller uncertainty inside the range
of the observed data. This arises from the greater flexibility of the 
Gaussian process, which describes a large family of possible curves.
Despite this flexibility, the GP can be described in relatively few 
parameters and is thus far less likely to overfit. 



Future directions
-----------------

### Higher dimensions 

In this simulated example, the underlying
dynamics are truly governed by a simple parametric model, allowing
the parametric approaches to be more accurate.  Similarly, because the
dynamics are  one-dimensional dynamics and lead to  stable nodes (rather
than other attractors such as limit-cycles resulting in oscillations),
the training data provides relatively limited information about the
dynamics.  For these reasons, we anticipate that in higher-dimensional
examples characteristic of ecosystem management problems that the machine
learning approach will prove even more valuable.


### Online learning

In our treatment here we have ignored the possibility of learning during the 
management phase, in which the additional observations of the stock size could
potentially improve parameter estimates.  While we intend to address this 
possibility in future work in the context of these non-parametric models,
we have not addressed it here for pedagogical reasons. In the context presented
here, it is clear that the differences in performance arise from differences
in the uncertainty inherent in the model formulations, rather than from 
differing abilities to learn.  Because we consider a threshold system, 
online learning would not change this generic feature of a lack of data in a
certain range of the state space which is better captured by the Gaussian process. 


Acknowledgments
===============

This work was partially supported by the Center for Stock Assessment
Research, a partnership between the University of California Santa Cruz
and the Fisheries Ecology Division, Southwest Fisheries Science Center,
Santa Cruz, CA and by NSFÂ grant EF-0924195 to MM and NSF grant DBI-1306697
to CB.


Appendix
========

## Model definitions and estimation

Equation S1: Ricker model.

$$X_{t+1} = Z_t X_t e^{r \left(1 - \frac{S_t}{K} \right) } $$

Figure S1: Ricker model: prior and posterior distributions for parameter estimates.

```{r, echo=FALSE, include=TRUE}
plot_ricker_traces
```

```{r, echo=FALSE, include=TRUE}
plot_ricker_posteriors
```
Table S1: Parameterization of the priors

```{r echo=FALSE, results="asis", include=TRUE}
xtable::xtable(data.frame(
  parameter = c("r0", "K", "sigma"),
  lower_bound = c(r0_prior_p[1], K_prior_p[1], stdQ_prior_p[1]),
  upper_bound = c(r0_prior_p[2], K_prior_p[2], stdQ_prior_p[2])))
```


$$ X_{t+1} = Z_t \frac{r S_t^{\theta}}{1 - \frac{S_t^\theta}{K}} $$

Eq S2: Myers model 
Figure S2: Myers model: Traces, prior and posterior distributions for parameter estimates.

```{r, echo=FALSE, include=TRUE}
plot_myers_traces
```

```{r, echo=FALSE, include=TRUE}
plot_myers_posteriors
```

Table S2: Parameterization of the priors
```{r echo=FALSE, results="asis", include=TRUE}
xtable::xtable(data.frame(parameter = c("r0", "K", "theta", "sigma"),
           lower_bound = c(r0_prior_p[1], K_prior_p[1], theta_prior_p[1], stdQ_prior_p[1]),
           upper_bound = c(r0_prior_p[2], K_prior_p[2], theta_prior_p[2], stdQ_prior_p[2])))
```


Eq S3: Allen model 

$$f(S_t) = S_t e^{r \left(1 - \frac{S_t}{K}\right)\left(S_t - C\right)} $$

Figure S3: Allen model: prior and posterior distributions for parameter estimates.

```{r, echo=FALSE, include=TRUE}
plot_allen_traces
```

```{r, echo=FALSE, include=TRUE}
plot_allen_posteriors
```

Table S3: Parameterization of the priors

```{r echo=FALSE, results="asis", include=TRUE}
xtable::xtable(data.frame(parameter = c("r0", "K", "theta", "sigma"),
           lower_bound = c(r0_prior_p[1], K_prior_p[1], theta_prior_p[1], stdQ_prior_p[1]),
           upper_bound = c(r0_prior_p[2], K_prior_p[2], theta_prior_p[2], stdQ_prior_p[2])))
```



Eq S4: GP model 
Figure S4: GP model: prior and posterior distributions for parameter estimates.

```{r echo=FALSE, include=TRUE}
gp_assessment_plots
```


Table S4: Parameterization of the priors

## Optimal Control Problem

We seek the harvest policy $h(x)$ that maximizes:

$$ \max_{h_t} \sum_{t \in 0}^{\infty}  \Pi_t(X_t, h_t) \delta^t  $$

subject to the profit function $\Pi(X_t,h)$, discount rate $\delta$, and the state
equation

$$X_{t+1} = Z_t f(S_t)  $$
$$S_t = X_t - h_t $$


Where $Z_t$ is multiplicative noise function with mean 1, representing
stochastic growth. We will consider log-normal noise with shape parameter
$\sigma_g$. 


Form this we can write down the Bellman recursion as: 

$$V_t(x_t) = \max_h \mathbf{E} \left(\Pi(h_t, x_t) + \delta V_{t+1}( Z_{t+1} f(x_t - h_t)) \right)$$

For simplicity we assume profit is simply linear in the realized harvest (only
enforcing the restriction that harvest can not exceed available stock), $\Pi(h,x) = min(h,x)$. 


### Pseudocode for the Bellman iteration

```r
 V1 <- sapply(1:length(h_grid), function(h){
      delta * F[[h]] %*% V +  profit(x_grid, h_grid[h]) 
    })
    # find havest, h that gives the maximum value
    out <- sapply(1:gridsize, function(j){
      value <- max(V1[j,], na.rm = T) # each col is a diff h, max over these
      index <- which.max(V1[j,])  # store index so we can recover h's 
      c(value, index) # returns both profit value & index of optimal h.  
    })
    # Sets V[t+1] = max_h V[t] at each possible state value, x
    V <- out[1,]                        # The new value-to-go
    D[,OptTime-time+1] <- out[2,]       # The index positions
```





### Training data

Eacho of our models $f(S_t)$ must be estimated from training data, which
we simulate from the Allen model with parameters $r = $ ` r p[1]`, 
$K =$ ` r p[2]`, $C =$ ` r p[3]`, and  $\sigma_g =$ ` r sigma_g` 
for $T=$ `r Tobs$ timesteps, starting at initial condition $X_0 = $ `r Xo`. 
The training data can be seen in Figure 1.  



-----------------------------------

<!-- OLD TEXT -->  



Abstract
=======================================================================


Decision-theoretic methods often rely on simple parametric models of
ecological dynamics to compare the value of a potential sequence of
actions. Unfortunately, such simple models rarely capture the complexity
or uncertainty found in most real ecosystems. 

Further, the data on which a model has been parameterized frequently 
fails to cover the possible state-space over which management decisions 
must operate.  Consequently a model do well in the region of state-space
in which it was estimated, but give erroneous confidence to predictions
outside of that region.  

This problem is keenly felt in any system where a potential threshold
or tipping point is a concern.  Such a tipping point, if it exists 
at all, will lay outside the observed range of the observed data. 


We demonstrate how nonparametric Bayesian models can provide robust,
solutions to decision making under uncertainty without knowing the 
structural form of the true model.  

While methods that account for _parametric_ uncertainty can be very 
successful with the right model,
structural uncertainty of not knowing what model best approximates the 
dynamics poses considerably greater difficulty.  



Introduction
=======================================================================

#### Opening 

<!-- More on complex dynamics and not having the correct model 


-->

<!-- More on the lack of data throughout the relevant state-space
     and how any concern about potential tipping points indicates 
     that the data exhibits this bias / problem.  
     -->




#### Models for decision-making under uncertainty 

Decision-theoretic or optimal control tools require a model that can assign probabilities of
future states (e.g. stock size of a fishery) given the current state and a
proposed action (e.g. fishing harvest or effort).  
Management frequently faces a sequential decision-making problem -- after 
selecting an action, the decision-maker may receive new information about 
the current state and must again choose an appropriate action -- such as setting
the harvest limits each year based on stock assessments the year prior.  

The decision maker typically seeks to determining the course of actions (also referred to as the policy)
that maximizes the expected value of some objective function such as
net present value derived from the resource over time.  
Though much can be said on how to choose this value function appropriately 
(e.g. see [@Halpern2013](http://doi.org/10.1073/pnas.1217689110 
"Achieving the triple bottom line in the face of inherent trade-offs 
among social equity, economic return, and conservation.")) we will
assume this is given.  (Nor is this approach necessarily constrained to 
maximizing the expectated value of such a function - the decision-theoretic
framework can be adapted to alternatives such as minimizing the maximum 
cost or damage that might be incurred; see @Polasky2011).

In representing future states with probabilities and maximizing expectations,
this approach provides a natural framework for handling uncertainty. 


The value function typically depends on the action or policy taken, as well as
the state of the system, in each interval of time. The state of the system,
in turn, is usually described by a dynamical model.


[@Williams2001; @Athanassoglou2012]. 


<!-- Transition and map: The weakness of parametric models -->
<!-- This section is a bit weak and vague.  Revisit to make a real map in light 
of outline structure below. -->

While simple mechanistic models can nevertheless provide important insights
into long-term outcomes, such approaches are not well-suited for use in
forecasting outcomes of potential management options.  Non-parametric
approaches offer a more flexible alternative that can both more accurately
reflect the data available while also representing greater uncertainty
in areas (of state-space) where data is lacking.

We demonstrate how
a Gaussian Process model of stock recruitment can lead to nearly optimal
management through stochastic dynamic programming, comperable to knowing
the correct structural equation for the underlying simulation.  Meanwhile,
parametric models that do not match the underlying dynamics can perform 
very poorly, even though they fit the data as well as the true model.  
Ecological research and management strategy should pay closer attention
to the opportunities and challenges nonparametric modeling can offer.



<!-- 
### Quantitative vs Qualitative Decisions

In this paper, we consider those ecological management problems in which
a mathematical (or computational) model is used to quantitatively inform
decision-making by allowing a manager to compare to the expected consequences
of potential management actions (or policies).  We distinguish this from the
solely qualitative use of a model, in which models are used to represent and
compare hypotheses of different mechanisms that would lead to qualitatively 
different actions. 

In addition to facing the potentially grave consequences of such transitions,
if they do exist in a system of interest, this generally means that we lack
data in the region near and beyond a possible tipping point.  As a consequence,
our models are least accurate just where we need them to be most accurate.  
Unfortunately, parametric modeling approaches are not well-suited to this 
scenario, in which good data is avialble over only part of the relevant 
state-space.  Necessary assumptions about model structure in any parametric
approach can lead such models to perform very poorly, even when accounting
for parameter uncertainty. 

-->


Approach and Methods
====================

## The optimal control problem in fisheries management

We focus on the problem in which a manager must set
the harvest level for a marine fishery each year to maximize the net
present value of the resource, given an estimated stock size from the
year before. 


<!-- ugh, re-word this -->

To permit comparisons against a theoretical optimum we will consider
data on the stock dynamics simulated from a simple parametric model
in which recruitment of the fish stock $X_{t+1}$ in the following year
is a stochastic process governed by a function $f$ of the current 
stock $X_t$, selected harvest policy $h_t$, and noise process $Z$,

$$X_{t+1} = Z_t f(X_t, h_t) $$


Given parameters for the function $f$ and probability distribution $Z$,
along with a given economic model determining the  price/profit $\Pi(X_t,
h_t)$ realized in a given year given a choice of harvest $h_t$ and
observed stock $X_t$.  This problem can be solved exactly for discretized
values of stock $X$ and policy $h$ using stochastic dynamic programming
(SDP) [@Mangel1985]. Problems of this sort underpin much marine fisheries
management today.

A crux of this approach is correctly specifying the functional form of $f$,
along with its parameters.  The standard approach uses one of a 
handful of common parametric models representing the stock-recruitment
relationship, usually after estimating the model parameters from any 
available existing data. Uncertainty in the parameter estimates can 
be estimated and integrated over to determine the optimal policy under
under uncertainty [@Mangel1985; @Schapaugh2013]. Uncertainty in the model
structure itself can only be addressed in this approach by hypothesizing 
alternative model structures, and then performing some model choice or
model averaging  [@Williams2001; @Athanassoglou2012]. 


## Underlying Model

Concerns over the potential for tipping points in ecological dynamics
[@Scheffer2001] highlight the dangers of uncertainty in ecological
management and pose a substantial challenge to existing decision-theoretic
approaches [@Brozovic2011].  Because intervention is often too late 
after a tipping point has been crossed (but see @Hughes2013), management
is most often concerned with avoiding potentially catastrophic tipping
points before any data is available at or following a transition that
would more clearly reveal these regime shift dynamics [e.g. @Bestelmeyer2012].

To illustrate the value of the non-parametric Bayesian approach to management,
we focus on example of a system containing such a tipping point whose dynamics
can still be described by a simple, one-dimensional parametric model.  
We will focus on a simple parametric model for a single species [derived
from fist principles by @Allen2005a] as our underlying "reality".

$$X_{t+1} = Z_t f(S_t)  $$
$$S_t = X_t - h_t $$
$$f(S_t) = S_t e^{r \left(1 - \frac{S_t}{K}\right)\left(S_t - C\right)} $$

Where $Z_t$ is multiplicative noise function with mean 1, representing
stochastic growth. We will consider log-normal noise with shape parameter
$\sigma_g$.  We start with an example in which the parameters are $r =2$,
$K=8$, $C=5$ and $\sigma_g = 0.1$.


<!-- ` r p[1]`, $K =$ ` r p[2]`, $C =$ ` r p[3]`, and  $\sigma_g =$ ` r sigma_g`. -->


As a low-dimensional system completely described by three parameters, this
scenario should if anything be favorable to a parametric-based approach.
This model contains an Allee effect, or tipping point, below which the
population is not self-sustaining and shrinks to zero [@Courchamp2008].


#### Simulated training data

We generate initial observational data under the model described in Eq 1 
for $T_{\textrm{obs}}=40$ time steps, under a given arbitrary sequence of harvest
intensities, $h_t$. 
We consider the case in which most of the data comes from a limited region
of state space (e.g. near a stable equilibrium), leaving us without
observations of the population dynamics at very low levels which would
be useful in discrimating between recruitment curves [@] or demonstrating
the existence of a tipping point [@Scheffer2001].  
Using data simulated from a specified model rather than empirical data
permits the comparison against the true underlying dynamics, setting 
a bar for the optimal performance possible.  



### Parametric Models

We consider three candidate parametric models for the stock-recruitment function, 
which we refer to by the first authors of the publications in which they were
first proposed.  

We generate the data with a four-parameter model that contains
a tipping point, as discussed above (equation 1),
(an Allee effect, see [@Allen, @Courchamp]) below which the stock
decreases to zero, 

$$ X_{t+1} = Z_t S_t e^{r \left(1 - \frac{S_t}{K}\right)\left(\frac{S_t - \theta}{K}\right)} $$

$$ S_t = X_t - h_t $$

The parameter $C$ reflects the location of the tipping point, $K$ the carrying capacity of
the stock, and $r$ the base recruitment rate.  $S_t$ represents the stock size after
a harvest $h_t$ has been implemented.  $Z_t$ represents a log-normal random variable of
log-mean zero and log-standard deviation parameter $\sigma$.  


We consider two alternative candidate models: the Ricker [@Ricker] stock-recruitment curve,

$$X_{t+1} = Z_t X_t e^{r \left(1 - \frac{S_t}{K} \right) } $$

and an alternative four-parameter model adapted from @Myers, 

$$ X_{t+1} = Z_t \frac{r S_t^{\theta}}{1 - \frac{S_t^\theta}{K}} $$

which contains a tipping point for $\theta > 2$ and becomes a Beverton-Holt model 
at $\theta = 1$.  

<!-- Note that while similarly-named parameters contain similar connotations, the 
estimate and precise intepretation will be different in each model. -->


### Bayesian Inference of Parametric models 

Given the sample data, we infer posterior distributions for each of the three
models listed above using a Markov Chain Monte Carlo Gibbs Sampler (jags, see 
appendix for implementation details and code) given uniform priors.  We run six
chains for $10^6$ steps each and then assess convergence by Gelman-Rubin criterion
and inspection of the traces, see appendix.  

<!-- By transforming variables we can integrate out the the $\sigma$ parameter
and the constant term in the log-mean, see appendix.  The resulting one or
two parameters can then be evaluated over a vector or grid of possible values,
and the result transformed back to determine the posterior density of the parameters,
This approach avoids any concerns of convergence in the MCMC analysis and can thus
be used to verify that the performance of the parametric models can not be explained
by convergence issues.  However, this approach does not generalize easily to richer models,
such as the introduction of measurement noise or additional parameters, in which 
MCMC based approaches are the obvious choice.  -->




### The Non-parametric Bayesian alternative for stock-recruitment curves



The use of Gaussian process (GP) regression (or "kriging" in the geospatial
literature) to formulate a predictive model is relatively new in the
context of modeling dynamical systems [@Kocijan2005] and introduced
in the ecological modeling and fisheries management by @Munch2005.
An accessible and thorough introduction to the formulation and use of
GPs can be found in @Rasmussen2006.

The essence of the GP approach can be captured in the
following thought experiment: An exhaustive parametric approach to the
challenge of structural uncertainty might proceed by writing down all
possible functional forms for the underlying dynamical system with all
possible parameter values for each form, and then consider searching
over this huge space to select the most likely model and parameters;
or using a Bayesian approach, assign priors to each of these possible
models and infer the posterior distribution of possible models. The
GP approach can be thought of as a computationally
efficient approximation to this approach. GPs represent
a large class of models that can be though of as capturing or reasonably
approximating the set of models in this collection.  By modeling at the
level of the process, rather than the level of parametric equation,
we can more concisely capture the possible behavior of these curves.
In place of a parametric model of the dynamical system, the GP 
approach postulates a prior distribution of (n-dimensional)
curves that can be though of as approximations to a range of possible
(parametric) models that might describe the data. The GP allows us
to consider probabilities on a large set of possible curves simultaneously.  


The posterior distribution for the hyper-parameters of the Gaussian 
process model are estimated by Metropolis-Hastings algorithm, again with
details and code provided in the Appendix.  @Rasmussen2006 provides
an excellent general introduction to Gaussian Processes and @Munch2005 
first discusses their application in the context of population dynamics
models such as fisheries stock-recruitment relationships.


### SDP via GP 

Once the posterior Gaussian process (GP) has been estimated [e.g. see
@Munch2005], it is necessary to adapt it in place of the parametric
equation for the stochastic dynamic programming (SDP) solution [see
@Mangel1988 for a detailed description of parametric SDP methods] to the
optimal policy. The essence of the idea is straight forward -- we will use
the estimated GP in place of the parametric growth function to determine
the stochastic transition matrix on which the SDP calculations are based.
The SDP is solved in a discretized state space -- both the continuously 
valued population densities $X$ and harvest quotas $h$ are first mapped to
a bounded, discrete grid.  (For simplicity we will consider a uniform grid,
though for either parametric or GP-based SDP it is often advantageous to 
use a non-uniform discretization such as a basis function representation,
e.g. see [@Deisenroth2009]). 

The SDP approach then computes a transition matrix, $\mathbf{F}$.  We 
demonstrate that calculation is just as straight forward based on the GP
as it is in the classical context using the parametric model.  The 
${i,j}$ of the transition matrix $F$ entry gives the probability of transitioning into 
state $x_i$ given that the system is in state $x_j$ in the previous 
time-step.  To generate the transition
matrix based on the posterior GP, we need only the expected values
at each grid point and the corresponding variances (the diagonal of
the covariance matrix), as shown in Figure 1.  Given the mean of the 
GP posterior at each grid-point as the vector $E$ and variance at that
point as vector $V$, the probability of transitioning from state $x_i$ to state $x_j$ is

$$\mathcal{N}\left(x_j | \mu = E_i, \sigma = \sqrt{V_i}\right)$$

where $\mathcal{N}$ is the Normal density at $x_j$ with mean $\mu$ and
variance $\sigma^2$.  Strictly speaking, the transition probability should
be calculated by integrating the normal density over the bin of width
$\Delta$ centered at $x_j$.  For a sufficiently fine grid that $f(x_j)
\approx f(x_j + \Delta)$, it is sufficient to calculate the density at
$x_j$ and then row-normalize the transition matrix. The process
can then be repeated for each possible discrete value of our control 
variable, (harvest $h$).  


**Pseudocode for the determining the transition matrix from the GP**

```r
for(h in h_grid)
  F_h = for(x_j in grid)
          for(i in 1:N) 
            dnorm(x_j, mu[i]-h, V[i])
```


Using the discrete transition matrix we may write down the Bellman
recursion defining the stochastic dynamic programming iteration:

\begin{equation}
V_t(x_t) = \max_h \mathbf{E} \left( h_t + \delta V_{t+1}( Z_{t+1} f(x_t - h_t)) \right)
\end{equation}

where $V(x_t)$ is the value of being at state $x$ at time $t$, $h$
is control (harvest level) chosen. Numerically, the maximization is
accomplished as follows. Consider the set of possible control values to
be the discrete values corresponding the grid of
stock sizes.  Then for each $h_t$ there is a corresponding transition
matrix $\mathbf{F}_h$ determined as described above but with mean 
$\mu = x_j - h_t$. Let $\vec{V_t}$ be the vector whose $i$th element corresponds
to the value of having stock $x_i$ at time $t$.  Then let $\Pi_h$ be
the vector whose $i$th element indicates the profit from harvesting
at intensity $h_t$ given a population $x_i$ (e.g. $\max(x_i, h_t)$
since one cannot harvest more fish then the current population size).
Then the Bellman recursion can be given in matrix form as

$$V_{t} = \max_h \left( \Pi_{h_{t}} + \delta \mathbf{F}_h V_{t+1} \right)$$

where the sum is element by element and the expectation is computed by the matrix multiplication $\mathbf{F} V_{t+1}$.  

### Pseudocode for the Bellman iteration

```r
 V1 <- sapply(1:length(h_grid), function(h){
      delta * F[[h]] %*% V +  profit(x_grid, h_grid[h]) 
    })
    # find havest, h that gives the maximum value
    out <- sapply(1:gridsize, function(j){
      value <- max(V1[j,], na.rm = T) # each col is a diff h, max over these
      index <- which.max(V1[j,])  # store index so we can recover h's 
      c(value, index) # returns both profit value & index of optimal h.  
    })
    # Sets V[t+1] = max_h V[t] at each possible state value, x
    V <- out[1,]                        # The new value-to-go
    D[,OptTime-time+1] <- out[2,]       # The index positions
```

This completes the algorithm adapting the GP to the sequential decision-making 
problem through SDP, which has not been previously demonstrated.  
We further provide an R package implementation as described in the supplemental materials.  


### Estimating parametric models 

We estimate posterior distributions for two parametric models: one using the structurally correct
model as given in Eq (1), which we refer to as the "Parametric Bayes" model,
and another using the familiar Ricker model, using a Gibbs sampler
as described (with source code) in the appendix).  In addition we 
estimate the parameters of the structurally correct model by maximum
likelihood.  
  

Results
=======

Discussion 
==========


#### Big picture: Linking GP to SDP  

_rambling_

Non-parametric Bayesian methods have received far too little attention
in ecological modeling efforts that are aimed at improved conservation
planning and decision making support.  Such approaches may be particularly
useful when the available data is restricted to a limited area of
state-space, which can lead parametric models to underestimate the
uncertainty in dynamics at population levels (states) which have not
been observed.  One reason for the relative absence of nonparametric
approaches in the natural resource management context may be the lack
of existing approaches for adapting the non-parametric Bayesian models
previously proposed [@Munch2005] to a decision-theoretic framework.
Adapting a non-parametric approach requires modification of existing
methods for decision theory.  We have illustrated how this might be
done for a classic stochastic dynamic programming problem, opening the
door for substantial further research into how these applications might
be improved.



<!-- On mechanistic models -->
<!-- { Seems kind of irrelevant }

The complexity of ecological interactions and a lack of data contribute
greatly to both of the problems. This concern is particularly acute
in case of ecological tipping points [@Barnosky2012; @Scheffer2001],
which arise from feedbacks common in ecological systems and can lead to a
sudden catastrophic transition to an undesirable state.  In general we do
not know where such tipping points are unless we have already observed
the transition, in which case it is frequently too late to respond.
Though there may exist early warning signals for certain kinds of these
transitions that are driven by slow changes [@Scheffer2009], we do not
know when, where, or how to apply them to the decision making context
more generally [@Boettiger2013]. 

--> 

----------------------------------------






Code to replicate the analysis, along with complete log of this research can be found at: [https://github.com/cboettig/nonparametric-bayes](https://github.com/cboettig/nonparametric-bayes/)


## Markov Chain Monte Carlo Analysis

```{r appendixplots, dependson="assemble-models"}
```


