% Avoiding tipping points in the management of ecological systems: a non-parametric Bayesian approach

<!-- Run R code for analysis, to be called by figures -->
```{r plot-options, cache=FALSE, message=FALSE, warning=FALSE, include=FALSE}
library(nonparametricbayes) 
opts_chunk$set(external=TRUE)
read_chunk("../examples/BUGS/external-chunks.R")

opts_chunk$set(tidy=FALSE, warning=FALSE, message=FALSE, cache=1, 
               comment=NA, verbose=TRUE, fig.width=4, fig.height=3)
 
# Name the cache path and fig.path based on filename...
opts_chunk$set(fig.path = paste("figure/",
                                gsub(".Rmd", "", knitr:::knit_concord$get('infile')),
                                "-", sep=""),
               cache.path = paste("cache/", 
                                  gsub(".Rmd", "", knitr:::knit_concord$get('infile') ), 
                                "/", sep=""))

toggle = "markup" #"hide"  # toggles `results` chunk option 

library(ggplot2) 
theme_set(theme_bw(base_size=12))
cbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", 
               "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
```

```{r posterior-mode}
```
```{r stateeq}
```
```{r sdp-pars, dependson="stateeq"}
```
```{r obs, dependson="sdp-pars"}
```


```{r mle, dependson="obs"}
```
```{r mle-output, dependson="mle", results=toggle}
```


```{r gp-priors}
```
```{r gp, dependson=c("gp-priors", "obs")}
```
```{r gp_traces_densities, dependson="gp"}
```
```{r gp-output, dependson="gp", results=toggle}
```


```{r jags-setup}
```
```{r common-priors}
```
```{r allen-model}
```
```{r allen-priors, dependson="common-priors"}
```
```{r allen-mcmc, dependson=c("allen-model", "allen-pars", "jags-setup"), results=toggle}
```
```{r allen-traces, dependson="allen-mcmc"}
```
```{r allen-posteriors, dependson=c("allen-traces", "allen-priors")}
```
```{r allen-output, dependson=c("posterior-mode", "allen-traces"), results=toggle}
```


```{r ricker-model}
```
```{r ricker-priors, dependson="common-priors"}
```
```{r ricker-mcmc, dependson="ricker-model", results=toggle}
```
```{r ricker-traces, dependson="ricker-mcmc"}
```
```{r ricker-posteriors, dependson=c("ricker-traces", "ricker-priors")}
```
```{r ricker-output, dependson=c("posterior-mode", "ricker-traces"), results=toggle}
```


```{r myers-model}
```
```{r myers-priors}
```
```{r myers-mcmc, dependson="myers-model", results=toggle}
```
```{r myers-traces, dependson="myers-mcmc"}
```
```{r myers-posteriors, dependson="myers-traces"}
```
```{r myers-output, dependson=c("posterior-mode", "myers-traces"), results=toggle}
```


```{r assemble-models, dependson=c("myers-output", "ricker-output", "allen-output", "gp-output", "mle-output")}
```
```{r gp-opt, dependson="gp-output"}
```
```{r mle-opt, dependson="mle-output"}
```
```{r allen-opt, dependson="allen-output"}
```
```{r ricker-opt, dependson="ricker-output"}
```
```{r myers-opt, dependson="myers-output"}
```
```{r assemble-opt, dependson=c("gp-opt", "mle-opt", "allen-opt", "ricker-opt", "myers-opt")}
```
```{r sims, dependson="assemble-opt"}
```


```{r profits, dependson="sims", results=toggle}
```

```{r dic_calc, dependson=c("posterior-mode", "myers-output", "ricker-output", "allen-output", "gp-output", "mle-output"), include=FALSE, echo=FALSE}
```



Abstract
========

Model uncertainty and limited data coverage are fundamental challenges to
robust ecosystem management.  These challenges are acutely highlighted
by concerns that many ecological systems may contain tipping points.
Before a collapse, we do not know where the tipping points lie, if the
exist at all.  Hence, we know neither a complete model of the system
dynamics nor do we have access to data in some large region of state-space
where such a tipping point might exist.  These two sources of uncertainty
frustrate state-of-the-art parametric approaches to decision theory
and optimal control.  I will illustrate how a non-parametric approach
using a Gaussian Process prior provides a more flexible representation
of this inherent uncertainty.  Consequently, we can adapt the Gaussian
Process prior to a stochastic dynamic programming framework in order to
make robust management predictions under both model and uncertainty and
limited data.


Introduction
============

Decision making under uncertainty is a ubiquitous challenge of
natural resource management and conservation.  Ecological dynamics are
frequently complex and difficult to measure, making uncertainty in our
understanding a prediction a persistent challenge to effective management.
Decision-theoretic approaches provide a framework to determine the
best sequence of actions in face of uncertainty, but only when that
uncertainty can be meaningfully quantified [@Fischer2009].  The sudden
collapse of fisheries and other ecosystems has increasingly emphasized
the difficulties of formulating even qualitatively correct models of
the underlying processes.


We develop these concerns in the context of fisheries, though
the underlying challenges and methods are germane to many other
conservation and resource management problems.  The economic value and
ecological concern have made marine fisheries the crucible for much
of the founding work [@Gordon1954; @Reed1979; @May1979; @Ludwig1982]
in managing ecosystems under uncertainty.  Global trends [@Worm2006]
and controversy [@Hilborn2007; @Worm2009] have made understanding these
challenges all the more pressing.

<!-- Uncertainty outside the data without the correct model has not been handled. -->
<!-- __We don't have the model__ -->

Uncertainty enters the decision-making process at many levels:
intrinsic stochasticity in biological processes, measurements, and
implementation of policy [_e.g._ @Reed1979; @Clark1986; @Roughgarden1996;
@Sethi2005], parameteric uncertainty [_e.g._ @Ludwig1982; @Hilborn1997;
@McAllister1998; @Schapaugh2013], and model or structural uncertainty
[_e.g._ @Williams2001; @Cressie2009;  @Athanassoglou2012].  Of these,
structural uncertainty incorporates the least a priori knowledge or
assumptions and is generally the hardest to quantify. Typical approaches
assume a weak notion of model uncertainty in which the correct model
(or reasonable approximation) of the dynamics must be identified from
among a handful of alternative models.  Here we consider an approach
that addresses uncertainty at each of these levels without assuming the
dynamics follow a particular (i.e. parametric) structure.



_Cut the next three paragraphs, since they are covered more consisely in the above paragraph?_

#### Process, measurement, and implementation error

Resource management and conservation planning seek to determine the
optimal set of feasible actions to maximize the value of some objectives
(see [@Halpern2012]).  Process error, measurement error, implementation
error [@Reed1979, @Clark1986, @Roughgarden1996, @Sethi2005].  These
sources of stochasticity in turn mean that model parameters can only
be estimated approximately, requiring parametric uncertainty also be
considered [@Ludwig1982].

#### Parametric uncertainty

As the parameter values for these models must be estimated from limited
data, there will always be some uncertainty associated with these values.
This uncertainty further compounds the intrinsic variability introduced
by demographic or environmental noise.  The degree of uncertainty in
the parameter values can be inferred from the data and reflected in the
estimates of the transition probabilities [@Walters1982; @Mangel1988;
@Mangel1997; @Schapaugh2013].

#### Structural (model) uncertainty

Estimates of parameter uncertainty are only as good as the parametric
models themselves.  Often we do not understand the system dynamics well
enough to know if a model provides a good approximation over the relevant
range of states and timescales (criteria that we loosely refer to as
defining the "right" or "true" model.)  So called structural or model
uncertainty is a more difficult problem than parametric uncertainty.
Typical solutions involve either model choice, model averaging, or
introducing yet greater model complexity of which others may be special
cases (model averaging being one such way to construct such a model)
[@Williams2001; @Athanassoglou2012; @Cressie2009].  Even setting aside
other computational and statistical concerns (e.g. [@Cressie2009]), these
approaches do not address our second concern - representing uncertainty
outside the observed data range.


<!-- __We don't have the data where we need it__ -->
<!-- What do we call this?  Extrapolation uncertainty?  Pathological Uncertainty? -->


Model uncertainty is particularly insidious when model predictions must
be made outside of the range of data on which the model was estimated.
This extrapolation uncertainty is felt most keenly in decision-theoretic
(or optimal control) applications, since (a) exploring the potential
action space typically involves considering actions that may move the
system outside the range of observed behavior, and (b) decision-theoretic
alogrithms rely not only on reasonable estimates of the expected
outcomes, but depend on the weights given to all possible outcomes
[_e.g._ @Weitzman2013].  If we are observing the fluctuations of a
given fish stock over many years under a fixed harvesting pressure,
we might develop and test a model that could reasonably predict the
frequency of a deviation of a given size, even when such a deviation has
not been previously observed. Yet such predictions are far less reliable
when extrapolated to a harvest pressure that has not yet been observed.
Thus, model uncertainty can be particularly challenging in the management
and decision-making context.


This difficult position of having neither the true model nor data that
covers the full range of possible states is unfortunately the rule more
than the exception. The potential concern of tipping points in ecological
dyanmics [@Scheffer2001; @Polasky2011] reflects these concerns -- as
either knowledge of the true model or more complete sampling of the
state space would make it easy to identify if a tipping point existed.
If we do not know but cannot rule out such a possibility, then we
face decision-making under this dual challege of model uncertainty and
incomplete data coverage.


These dual concerns pose a substantial challenge to existing decision-theoretic
approaches [@Brozovic2011].  Because intervention is often too late 
after a tipping point has been crossed (but see @Hughes2013), management
is most often concerned with avoiding potentially catastrophic tipping
points before any data is available at or following a transition that
would more clearly reveal these regime shift dynamics [e.g. @Bestelmeyer2012].

<!--
_Map_
-->

Here we illustrate how a stochastic dynamic programming (SDP) algorithm
[@Mangel1988; @Marescot2013] can be driven by the
predictions from a Bayesian non-parametric (BNP) approach [@Munch2005a].
This provides two distinct advantages compared with contemporary
approaches.  First, using a BNP sidesteps the need for an accurate
model-based description of the system dynamics.  Second, the BNP can
better reflect uncertainty that arises when extrapolating a model outside
of the data on which it was fit.  We illustrate that when the correct
model is not known, this latter feature is crucial to providing a robust
decision-theoretic approach in face of substantial structural uncertainty.





<!-- necessary? --> <!-- should reflect the dual problem of extrapolation and model uncertainty better -->

This paper represents the first time the SDP decision-making framework has
been used without an a priori model of the underlying dynamics through
the use of the BNP approach.  In contrast to parametric models which
can only reflect uncertainty in parameter estimates, the BNP approach
provides a more state-space dependent representation of uncertainty.
This permits a much greater uncertainty far from the observed data than
near the observed data.  These features allow the GP-SDP approach to
find robust management solutions in face of limited data and without
knowledge of the correct model structure.



<!--
-  _Note on "not magic"_: honest uncertainty + SDP
--> 

The idea that any approach can perform well without either having to
know the model or have particularly good data should immediately draw
suspicion.  The reader must bear in mind that the strength of our approach
comes not from black-box predictive power from such limited information,
but rather, by providing a more honest expression of uncertainty outside
the observed data without sacrificing the predictive capacity near the
observed data. By coupling this more accurate description of what is known
and unknown to the decision-making under uncertainty framework provided
by stochastic dynamic programming, we are able to obtain more robust
management policies than with common parametric modeling approaches.



<!--move to  much later *Or do we need this at all?* 
- _Note on comparing models_ (via value function rather than by "fit"). 
-->

The nature of decision-making problems provides a convenient way to compare 
models.  Rather than compare models in terms of best fit to data or fret over
the appropriate penalty for model complexity, model performance is defined 
in the concrete terms of the decision-maker's objective function, which we
will take as given. (Much argument can be made over the 'correct' objective
function, e.g. how to account for the social value of fish left in the sea
vs. the commercial value of fish harvested; see @Halpern2013 for further 
discussion of this issue.  Alternatively, we can always compare model performance
across multiple potential objective functions.)  The decision-maker
does not necessarily need a model that provides the best mechanistic understanding
or the best long-term outcome, but rather the one that best estimates the 
probabilities of being in different states as a result of the possible actions. 



## Background on the Gaussian Process

<!-- 
- Background on non-parametric modeling.  
-->


Addressing the difficulty posed by extrapolation without knowing the
true model requires a nonparametric approach to model fitting: one
that does not assume a fixed structure but rather depends on the size
of the data (e.g. non-parametric regression or a Dirichlet process).
This established terminology is nevertheless unfortunate, as (a)
this approach still involves the estimation of parameters, and (b),
Statisticians use non-parametric to mean both this property (structure
is not fixed by the parameters) and an entirely different (and probably
more familiar) case in which the model does not assume any distribution
(e.g. non-parametric bootstrap, order statistics).  Some literature
thus uses the term semi-parametric, which merely adds ambiguity to
the confusion.

This non-parametric property -- having a structure explicitly dependent on
the data -- is precisely the property that makes this approach attractive
in face of the limited data sampling challenges discussed above.
Having fit a parametric model to some data, the model is completely
described by the values (or posterior distributions) of it's parameters.
The non-parametric model is not captured by its parameter values or
distributions alone. Either the model scales with the complexity of the data
on which it is estimated (e.g. nonparametric heirarchical approaches such
as the Dirchlet process) or the data points become themselves part of the model
specification, as in the nonparametric regression used here.

<!--
- Definition
- Previous application
--> 

The use of Gaussian process (GP) regression (or "kriging" in the geospatial
literature) to formulate a predictive model is relatively new in the
context of modeling dynamical systems [@Kocijan2005], and was first introduced
in the context ecological modeling and fisheries management in @Munch2005.
An accessible and thorough introduction to the formulation and use of
GPs can be found in @Rasmussen2006.

<!--
- Why it is particularly suited to these two problems
- (Why this is a novel application thereof)
--> 

<!-- Useless 
The essence of the GP approach can be captured in the following
thought experiment: An exhaustive parametric approach to the challenge
of structural uncertainty might proceed by writing down all possible
functional forms for the underlying dynamical system with all possible
parameter values for each form, and then consider searching over this
huge space to select the most likely model and parameters; or using a
Bayesian approach, assign priors to each of these possible models and
infer the posterior distribution of possible models. The GP approach
can be thought of as a computationally efficient approximation to this
approach. GPs represent a large class of models that can be though
of as capturing or reasonably approximating the set of models in this
collection.  By modeling at the level of the process, rather than the
level of parametric equation, we can more concisely capture the possible
behavior of these curves.  In place of a parametric model of the dynamical
system, the GP approach postulates a prior distribution of (n-dimensional)
curves that can be though of as approximations to a range of possible
(parametric) models that might describe the data. The GP allows us to
consider probabilities on a large set of possible curves simultaneously.
-->

The posterior distribution for the hyper-parameters of the Gaussian 
process model are estimated by Metropolis-Hastings algorithm, again with
details and code provided in the Appendix.  @Rasmussen2006 provides
an excellent general introduction to Gaussian Processes and @Munch2005 
first discusses their application in the context of population dynamics
models such as fisheries stock-recruitment relationships.


Approach and Methods
====================

<!-- skip this oveview? 
### Summary of approach
--> 



### Statement of the optimal control problem

To illustrate the application of the BNP-SDP approach and compare to the
predictions of the alternative parametric models we focus on the classical
problem of selecting the appropriate harvest level given an observation
of the stock size in the previous year  [@Reed1979; @Walters1982, @Mangel1988].
Given this observation and the model (together with the parameter uncertainty) of the stock
recruitment process, the manager seeks to maximize the value of the 
fishery over a fixed time interval of `r OptTime` years at a discount rate
of `r delta`. The value function (profits) at time $t$ depends on the true stock size
$x_t$ and the chosen harvest level $h_t$.  For simplicity we assume profit 
is simply proportional in the realized harvest (only
enforcing the restriction that harvest can not exceed available stock).  


### Parametric models

<!-- 
- Statement of the models
--> 

We consider three candidate parametric models of the stock-recruitment
dynamics: The Ricker model, the Allen model [@Allen2005], the Myers
model [@Myers1995]. The familiar Ricker model involves two parameters, corresponding
to a growth rate and a carrying capacity, and cannot support alternative
stable state dynamics (though as growth rate increases it exhibits a
periodic attractor that proceeds through period-doubling into chaos. We
will generally focus on dynamics below the chaotic threshold for
the purposes of this analysis.) The Allen model resembles the Ricker
dynamics with an added Allee effect parameter [@Courchamp2008], below
which the population cannot persist.  The Myers model also has three
parameters and contains an Allee threshold, but has compensatory rather
than over-compensatory density dependence (resembling a Beverton-Holt
curve rather than a Ricker curve at high densities.)

We assume multiplicative log-normal noise perturbs the growth predicted 
by the each of the deterministic model skeletons described above. This 
introduces one additional parameter $\sigma$ that must be estimated by each
model. 

<!-- equations just in appendix? -->

As we simulate training data from the Allen model, we will
refer to this as the structurally correct model.  The Ricker model is
thus a reasonable approximation of these dynamics far from the Allee
threshold (but lacks threshold dynamics), while the Myers model shares
the essential feature of a threshold but differs in the structure. Thus
we have three potential parametric models of the stock dynamics.

We introduce parameteric uncertainty by first estimating each of the
candidate models from data on unexploited stock dynamics following
some pertubation (non-equilibrium initial condition) over several time
steps. This training data could be generated in several different ways
(such as known variable exploitation rates, etc), as long as it reflects
the dynamics in some limited region of state space without impacting
the problem.  We consider a period of `r Tobs` years of training data: long
enough that the estimates are not dependent on the particular realization,
while longer times are not likely to provide substantial improvement
(i.e. the results are not sensitive to this interval).  Each of the models
(described below) is fit to the same training data, as shown in Figure 1.


<!-- Bayesian inference of parametric models --> 

We infer posterior distributions for the parameters of each model
in a Bayesian context using Gibbs sampling (implemented in R [@RTeam]
using jags, [@R2jags]).  We choose uninformative uniform priors for all
parameters (See Appendix, Figures S1-S3, and Table S1, and the R code
provided). One-step-ahead predictions of these model fits are shown in
Figure 1.

<!-- SDP via parametric models -->

An optimal policy function is then inferred through stochastic dynamic
programming for each model given the posterior distributions of the
parameter estimates.  This policy maximizes the expectation of the value
function integrated over the parameter uncertainty. (code implementing
this algorithm provided in the Appendix).


### The Gaussian Process model

<!-- Statement of model -->  

<!-- FIXME ... say much more about the GP, as per Munch 2005a   -->
<!-- See much longer discusion above on "Background on GP".  Move some of that to here?  -->


We also estimate a simple Gaussian Process defined by
a radial basis function kernel of two parameters: $\ell$, which gives
the characteristic length-scale over which correlation between two 
points 
in state-space decays, and $\sigma$, which gives the scale of the 
process noise by which observations $Y_{t+1}$ may differ from their
predicted values $X_{t+1}$ given an observation of the previous state,
$X_t$. @Munch2005a gives an accessible introduction to the use of 
Gaussian Processes in providing a Bayesian nonparametric description
of the stock-recruitment relationship.  

<!-- Inference of the BNP model --> 

In contrast to the parametric models, this posterior distribution is still
conditional on the training data. As such, the uncertainty near the
observed data.

We use a Metropolis-Hastings Markov Chain Monte Carlo to infer posterior
distributions of the two parameters of the GP (Figure S4, code in
appendix), under weakly informative Gaussian priors (see parameters in
table S5). As the posterior distributions differ substantially from the
priors (Figure S4), we can be assured that most of the information in
the posterior comes from the data rather than the prior belief.


<!-- SDP via the model --> 

Though we are unaware of prior application of this type, it is reasonably
straight-forward to adapt the Gaussian Process for Stochastic Dynamic
Programming.  Recall that unlike the parametric models the Gaussian
process with fixed parameters already predicts a distribution of
curves rather than a single curve. We must first integrate over 
this distribution of curves given a sampling of parameter values drawn
from the posterior distribution of the two GP parameters, before
integrating over the posterior of those parameters themselves.



Results
=======

<!-- 
### Figure 1: Fitted Models

- All models fit the data quite well
- Information criteria would pick the simple, incorrect model.
--> 


```{r Figureb_posteriors, dependson=c("assemble-models", "par-fns"), include=TRUE, echo=FALSE, fig.cap="Points show the training data of stock-size over time.  Curves show the posterior step-ahead predictions based on each of the estimated models.", fig.width=8, fig.height=6}
```

All models fit the observed data rather closely and with relatively small uncertainty, as illustrated in the posterior predictive curves in Figure 1.  Figure 1 shows the training data of stock sizes observed over time as points, overlaid with the step-ahead predictions of each estimated model using the parameters sampled from their posterior distributions.  Each model manages to fit the observed data rather closely. Compared to the expected value of the true model most estimates appear to overfit, predicting fluctuations that are actually due purely to stochasticity in growth rate.  Model-choice criteria shown in Table 1 penalize more complex models and show a slight preference for the simpler Ricker model over the more complicated alternate stable state models (Allen and Myers).  Details on MCMC estimates for each model, traces, and posterior distributions can be found in the appendix.   

```{r deviances, dependson=c("dic_calc"), include=FALSE, echo=FALSE}
```

```{r Table1, dependson="deviances", include=TRUE, results="asis", echo=FALSE}
xtable::xtable(rbind(dictable, aictable, bictable))
```


<!-- 
### Figure 2 
- Data comes from limited region of state-space 
- (Should really show uncertainty of all models here.  Capture the forecast uncertainty several steps down the road?)   
-->

```{r statespace_posteriors, dependson=c("assemble-models"), fig.cap="Graph of the inferred Gaussian process compared to the true process and maximum-likelihood estimated process.  Graph shows the expected value for the function $f$ under each model.  Two standard deviations from the estimated Gaussian process covariance with (light grey) and without (darker grey) measurement error are also shown.  The training data is also shown as black points.  The GP is conditioned on (0,0), shown as a pseudo-data point.", include=TRUE, echo=FALSE, fig.width=8, fig.height=6}
```

The mean inferred state space dynamics of each model relative to the
true model used to generate the data is shown in Figure 2, predicting
the relationship between observed stock size (x-axis) to the stock
size after recruitment the following year.  Note that in contrast to
the  other models shown, the expected Gaussian process corresponds to a
distribution of curves - as indicated by the gray band - which itself
has a mean shown in black. Parameter uncertainty (not shown) spreads
out the estimates further.  The observed data from which each model is
estimated is also shown.  The observations come from only a limited region
of state space corresponding to unharvested or weakly harvested system.
No observations occur at the theoretical optimum harvest rate or near
the tipping point.



```{r out_of_sample_predictions, include=TRUE, echo=FALSE, fig.width=8, fig.height=6, fig.cap="Out of sample predictions of the dynamics under each model.  Points show the stock size simulated by the true model.  Overlay shows the range of states predicted by each model, based on the state observed in the previous time step. The Ricker model always predicts population growth, while the actual population shrinks in each step as the initial condition falls below the Allee threshold of the underlying model (Allen).  Note that the GP is both more pessimistic and more uncertain about the future state than the parameteric models, while the realized state often falls outside of the expected range forecasted by the structurally incorrect Myers and Ricker models." }
```




<!--
### Figure 3: Inferred Policies

- Inferred policies differ substantially among models
- The structurally correct model and the GP are close to the true model
- alternatives are not close
--> 


```{r Figure2, dependson = c("assemble-opt"), fig.cap="The steady-state optimal policy (infinite boundary) calculated under each model.  Policies are shown in terms of target escapement, $S_t$, as under models such as this a constant escapement policy is expected to be optimal [@Reed1979].", include=TRUE, echo=FALSE}
```

Despite the similarities in model fits to the observed data, the
policies inferred under each model differ widely, as shown in Figure 3.
Policies are shown in terms of target escapement, $S_t$.  Under models
such as this a constant escapement policy is expected to be optimal
[@Reed1979], whereby population levels below a certain size $S$ are
unharvested, while above that size the harvest strategy aims to return the
population to $S$, resulting in the hockey-stick shaped policies shown.
Only the structurally correct model (Allen model) and the GP produce
policies close to the true optimum policy (where both the underlying
model structure and parameter values are known without error).


```{r Figure3, dependson=c("sim"), fig.cap="Gaussian process inference outperforms parametric estimates. Shown are 100 replicate simulations of the stock dynamics (eq 1) under the policies derived from each of the estimated models, as well as the policy based on the exact underlying model.",  include=TRUE, echo=FALSE}
```

The consequences of managing 100 replicate realizations of the simulated
fishery under each of the policies estimated is shown in Figure 4.
As expected from the policy curves, the structurally correct model
under-harvests, leaving the stock to vary around it's un-fished optimum.
The structurally incorrect Ricker model over-harvests the population
passed the tipping point consistently, resulting in the immediate crash
of the stock and thus derives minimal profits.

These results are robust across a range of stochastic realizations,
models, and parameter values.  The results across this range can most
easily be compared by using the relative differences in net present
value realized by each of the model, as shown in Figure 5.  The BNP-SDP
approach most consistently realizes a value close to the optimal solution,
and importantly avoids ever driving the system across the tipping point,
which results in the near-zero value cases in the parametric models.


```{r Figure4, dependson=c("profits"), fig.cap="Histograms of the realized net present value of the fishery over a range of simulated data and resulting parameter estimates. For each data set, the three models are estimated as described above. Values plotted are the averages of a given policy over 100 replicate simulations. Details and code provided in the supplement.",  include=TRUE, echo=FALSE}

```


Discussion 
==========


In any modeling effort, models must be chosen for the task at hand.  
Though simple mechanistically motivated models offer the greatest potential 
to increase our basic understanding of ecological processes [@Cuddington2013; @Geritz2012], 
such models can be not only inaccurate but misleading when relied upon in a
quantitative decision making framework.  
In this paper we have tackled two aspects of uncertainty that are both common
to many ecological desicion-making problems and fundamentally challenging to
existing approaches which largely rely on parametric models: 

1. We do not know what the correct models are for ecological systems.
1. We have limited data from which to estimate the model -- in particular,
   such models may be misleading in predicting the probability of outcomes
   outside the training data.  

We have illustrated how the use of non-parametric approaches can provide
more reliable solutions in the sequential decision-making problem. 

### Traditional model-choice approaches can be positively misleading.  

These results illustrate that model-choice approaches would be positively
misleading -- supporting simpler models that cannot express tipping point
dynamics merely on account of them being similar.  As the data shown
comes only from the basin of attraction near the unfished equilibrium,
near which all of the models are approximately linear and approximately
identical. 

Model choice approaches trade off model complexity and fit to the data. 
When the data come from a limited region of state-space -- as is necessarily 
the case whenever there is a potential concern about tipping point dynamics --
simpler models can fit just as well and will tend to outperform more complex 
ones.  This approach would be appropriate when the dynamics can be expected 
to remain in the region of the training data; for instance, if we only 
considered the forecasting accuracy of the unfished population dynamics under
each model.  

In contrast, the decision-maker's problem of setting appropriate harvest levels
cannot exclude regions of state-space outside the observed range when integrating
over all possible decisions to find the optimal choice.  Such problems are not 
constrained to fisheries management but ubiquitous across ecological decision-making
and conservation where the greatest concerns involve entering previously unobserved
regions of state-space -- whether that is the collapse of a fishery, the spread
of an invasive, or the loss of habitat.  

### BNP-SDP expresses larger uncertainty in regions where the data are poor 

The parametric models perform worst when they propose a management strategy
outside the range of the observed data. The non-parametric Bayesian approach, 
in contrast, allows a predictive model that expresses a great deal of uncertainty
about the probable dynamics outside the observed range, while retaining very
good predictive accuracy in the range observed.  The management policy 
dictated by the GP balance this uncertainty against
the immediate value of the harvest, and act to stabilize the population 
dynamics in a region of state space in which the predictions can be 
reliably reflected by the data.  

### BNP-SDP has good predictive accuracy where data are good

While expressing larger uncertainty outside the observed data, the GP
can also provide a better fit with smaller uncertainty inside the range
of the observed data. This arises from the greater flexibility of the 
Gaussian process, which describes a large family of possible curves.
Despite this flexibility, the GP can be described in relatively few 
parameters and is thus far less likely to overfit. 

### Risk-prone and risk-adverse value functions

The degree to which the decision-making part of the algorithm (the SDP)
chooses to explore or avoid the resulting region of uncertainty can also
be influenced by the curvature of the value (profit) function $\Pi$. Both
to simplify the intution and avoid biasing this result, we have chosen
a profits that are linear in the catch and thus neither risk-prone nor
risk adverse.  Making this function concave, representing the typical
assumption of diminishing returns, would make the SDP more risk-adverse
(as larger-than-expected stock sizes offer dimished returns relative
to the cost of smaller-than-expected stock sizes), and strengthen the
result shown here in which the BNP solution tends to avoid the region
of uncertainty.  Sufficiently convex or risk-prone functions could lead
the SDP to attempt higher exploitation rates despite the uncertainty.
Understanding the relative roles of such functions would be a promising
direction for future investigation.


### The role of the prior

Lastly, it should be noted that outside the data, the NBP reverts to
the prior, and consequently the choice of the prior can also play a
significant role in determining the optimal policy inferred by the
SDP.  In the examples shown here we have selected a prior that is both
relatively uninformative (due to the broad priors placed on its parameters
$\ell$ and $\sigma$ and simple (mean zero, radial basis function kernel).
In practice, both the choice of mean and the choice of the covariance
function may be chosen to confer particular biological properties,
as well as more biologically informed priors for $\ell$ and $\sigma$.
In principle, this may allow a manager to improve the performance of the
BNP-SDP approach by adding only enough additional detail as is justified.
For instance, it would be possible to use a linear or a Ricker-shaped
mean in the prior without making the much stronger assumption that the
Ricker is the structurally correct model.  However, this influence raises
challenges as well.  For instance, in choosing a trivial mean-zero prior,
we bias the dynamics to transitions to 0 in step $X_{t+1}$ from any
stock size $X_t$ in the prior year, in the absence of any other data.
Future research must make sure that both the prior and the value function
are chosen appropriately for the problem at hand.



Future directions
-----------------

### Higher dimensions 

In this simulated example, the underlying dynamics are truly governed
by a simple parametric model, allowing the parametric approaches to be
more accurate.  Similarly, because the dynamics are  one-dimensional
dynamics and lead to  stable nodes (rather than other attractors such
as limit-cycles resulting in oscillations), the training data provides
relatively limited information about the dynamics.  For these reasons,
we anticipate that in higher-dimensional examples characteristic of
ecosystem management problems that the machine learning approach will
prove even more valuable.


### Real-time learning

In our treatment here we have ignored the possibility of learning during
the management phase, in which the additional observations of the stock
size could potentially improve parameter estimates.  Of particular
interest in the context of the extreme uncertainty considered here
is the notion of "active adaptive management" or "adaptive probing",
which may actively seek to reduce uncertainty.  The concept of adaptive
probing is one area that has explicitly addressed the extrapolation
uncertainty addressed here, though typically without the additional
issue of model uncertainty.  As a result, adaptive probing strategies
suggest rather opposite conclusions than what we observe here. Such
adaptive probing or Dual Control (e.g. @Ludwig1982) approaches trade
off short term utility by choosing actions that can reduce uncertainty.
Adaptive probing strategies arise when it is valuable to intentionally
force a system far from the observed values even when the expected value
such actions is low, as it provides much faster learning and consequent
reduction of model uncertainty that can allow greater value to be derived
later on.  For instance, @Ludwig1982 show that it may be advantageous
to fish an unexploited population very heavily at first to obtain a
better estimate of the recruitment rate.  This intuitive strategy when a
population is governed by a Ricker or Beverton-Holt-like dynamic would
clearly be disastrous if instead the dynamics contained an unforeseen
tipping point.  The best way to learn where the edge lies may be to
walk up to it, but it is also the most dangerous.  Future work should
attempt to understand when such active adaptive learning is valuable,
and when it will increase the risk of an irreversible transition.


Acknowledgments
===============

This work was partially supported by the Center for Stock Assessment
Research, a partnership between the University of California Santa Cruz
and the Fisheries Ecology Division, Southwest Fisheries Science Center,
Santa Cruz, CA and by NSFÂ grant EF-0924195 to MM and NSF grant DBI-1306697
to CB.


Appendix
========

## Model definitions and estimation

Equation S1: Ricker model.

$$X_{t+1} = Z_t X_t e^{r \left(1 - \frac{S_t}{K} \right) } $$

Figure S1: Ricker model: prior and posterior distributions for parameter estimates.

```{r, echo=FALSE, include=TRUE, fig.height=6, fig.cap="Traces from the MCMC estimate of the Ricker model", fig.width=8}
plot_ricker_traces
```

```{r, echo=FALSE, include=TRUE, fig.cap="Posteriors from the MCMC estimate of the Ricker model", fig.width=8}
ggplot(ricker_posteriors, aes(value)) + 
  stat_density(geom="path", position="identity", alpha=0.7) +
  facet_wrap(~ variable, scale="free", ncol=2)
```
Table S1: Parameterization of the priors

```{r echo=FALSE, results = "asis", include = TRUE}
xtable::xtable(data.frame(
  parameter = c("r0", "K", "sigma"),
  lower_bound = c(r0_prior_p[1], K_prior_p[1], stdQ_prior_p[1]),
  upper_bound = c(r0_prior_p[2], K_prior_p[2], stdQ_prior_p[2])))
```


$$ X_{t+1} = Z_t \frac{r S_t^{\theta}}{1 - \frac{S_t^\theta}{K}} $$

Eq S2: Myers model 
Figure S2: Myers model: Traces, prior and posterior distributions for parameter estimates.

```{r, echo=FALSE, include=TRUE, fig.height=6, fig.cap="Traces from the MCMC estimate of the Myers model", fig.width=8}
plot_myers_traces
```

```{r, echo=FALSE, include=TRUE, fig.cap="Posterior distributions from the MCMC estimates of the Myers model", fig.width=8}
ggplot(myers_posteriors, aes(value)) + 
  stat_density(geom="path", position="identity", alpha=0.7) +
  facet_wrap(~ variable, scale="free", ncol=3)
```

Table S2: Parameterization of the priors
```{r echo=FALSE, results="asis", include = TRUE}
xtable::xtable(data.frame(parameter = c("r0", "K", "theta", "sigma"),
           lower_bound = c(r0_prior_p[1], K_prior_p[1], theta_prior_p[1], stdQ_prior_p[1]),
           upper_bound = c(r0_prior_p[2], K_prior_p[2], theta_prior_p[2], stdQ_prior_p[2])))
```


Eq S3: Allen model 

$$f(S_t) = S_t e^{r \left(1 - \frac{S_t}{K}\right)\left(S_t - C\right)} $$

Figure S3: Allen model: prior and posterior distributions for parameter estimates.

```{r, echo=FALSE, include=TRUE, fig.height=6, fig.cap="Traces from the MCMC estimate of the Allen model", fig.width=8}
plot_allen_traces
```

```{r, echo=FALSE, include=TRUE, fig.cap="Posteriors from the MCMC estimate of the Allen model", fig.width=8}
ggplot(allen_posteriors, aes(value)) + 
  stat_density(geom="path", position="identity", alpha=0.7) +
  facet_wrap(~ variable, scale="free", ncol=3)
```

Table S3: Parameterization of the priors

```{r echo=FALSE, results = "asis", include=TRUE}
xtable::xtable(data.frame(parameter = c("r0", "K", "theta", "sigma"),
           lower_bound = c(r0_prior_p[1], K_prior_p[1], theta_prior_p[1], stdQ_prior_p[1]),
           upper_bound = c(r0_prior_p[2], K_prior_p[2], theta_prior_p[2], stdQ_prior_p[2])))
```



Eq S4: GP model 
Figure S4: GP model: prior and posterior distributions for parameter estimates.

```{r echo=FALSE, include=TRUE}
gp_assessment_plots
```


Table S4: Parameterization of the priors

## Optimal Control Problem

We seek the harvest policy $h(x)$ that maximizes:

$$ \max_{h_t} \sum_{t \in 0}^{\infty}  \Pi_t(X_t, h_t) \delta^t  $$

subject to the profit function $\Pi(X_t,h)$, discount rate $\delta$, and the state
equation

$$X_{t+1} = Z_t f(S_t)  $$
$$S_t = X_t - h_t $$


Where $Z_t$ is multiplicative noise function with mean 1, representing
stochastic growth. We will consider log-normal noise with shape parameter
$\sigma_g$. 


Form this we can write down the Bellman recursion as: 

$$V_t(x_t) = \max_h \mathbf{E} \left(\Pi(h_t, x_t) + \delta V_{t+1}( Z_{t+1} f(x_t - h_t)) \right)$$

For simplicity we assume profit is simply linear in the realized harvest (only
enforcing the restriction that harvest can not exceed available stock), $\Pi(h,x) = min(h,x)$. 


### Pseudocode for the Bellman iteration

```r
 V1 <- sapply(1:length(h_grid), function(h){
      delta * F[[h]] %*% V +  profit(x_grid, h_grid[h]) 
    })
    # find havest, h that gives the maximum value
    out <- sapply(1:gridsize, function(j){
      value <- max(V1[j,], na.rm = T) # each col is a diff h, max over these
      index <- which.max(V1[j,])  # store index so we can recover h's 
      c(value, index) # returns both profit value & index of optimal h.  
    })
    # Sets V[t+1] = max_h V[t] at each possible state value, x
    V <- out[1,]                        # The new value-to-go
    D[,OptTime-time+1] <- out[2,]       # The index positions
```





### Training data

Eacho of our models $f(S_t)$ must be estimated from training data, which
we simulate from the Allen model with parameters $r = $ ` r p[1]`, 
$K =$ ` r p[2]`, $C =$ ` r p[3]`, and  $\sigma_g =$ ` r sigma_g` 
for $T=$ `r Tobs` timesteps, starting at initial condition $X_0 = $ `r Xo`. 
The training data can be seen in Figure 1.  


### Sensitivity Analysis



